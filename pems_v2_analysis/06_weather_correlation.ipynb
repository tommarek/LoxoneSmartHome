{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Correlation Analysis\n",
    "\n",
    "## Objectives:\n",
    "1. Analyze correlations between weather conditions and energy systems\n",
    "2. Quantify weather impact on PV production, heating demand, and total consumption\n",
    "3. Develop weather-based prediction models\n",
    "4. Identify optimal weather conditions for energy efficiency\n",
    "5. Create weather features for energy management optimization\n",
    "\n",
    "## Key Analyses:\n",
    "- PV production vs solar radiation correlation\n",
    "- Temperature impact on heating demand\n",
    "- Weather influence on total energy consumption\n",
    "- Seasonal weather pattern analysis\n",
    "- Weather-based forecasting model development\n",
    "- Extreme weather event analysis\n",
    "- Weather optimization recommendations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport sys\nimport os\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport asyncio\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import pearsonr, spearmanr\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Add pems_v2 directory to path for imports\nsys.path.append(str(Path('./pems_v2').resolve()))\n\n# Import project modules\nfrom analysis.core.data_extraction import DataExtractor\nfrom config.settings import PEMSSettings\n\n# Set up plotting style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\n%matplotlib inline"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Weather and Energy Data\n",
    "\n",
    "Load comprehensive weather data and all energy system data for correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize settings and extractors\n",
    "settings = PEMSSettings()\n",
    "extractor = DataExtractor(settings)\n",
    "\n",
    "# Define analysis period (last 150 days for comprehensive weather analysis)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=150)\n",
    "\n",
    "print(f\"Analysis period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weather and energy data\n",
    "async def load_weather_and_energy_data():\n",
    "    \"\"\"Load comprehensive weather and energy data.\"\"\"\n",
    "    print(\"Loading weather forecast data...\")\n",
    "    weather_data = await extractor.extract_weather_data(start_date, end_date)\n",
    "    \n",
    "    print(\"Loading current weather data...\")\n",
    "    try:\n",
    "        current_weather = await extractor.extract_current_weather(start_date, end_date)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load current weather: {e}\")\n",
    "        current_weather = pd.DataFrame()\n",
    "    \n",
    "    print(\"Loading PV production data...\")\n",
    "    pv_data = await extractor.extract_pv_data(start_date, end_date)\n",
    "    \n",
    "    print(\"Loading energy consumption data...\")\n",
    "    consumption_data = await extractor.extract_energy_consumption(start_date, end_date)\n",
    "    \n",
    "    print(\"Loading room temperature data...\")\n",
    "    room_data = await extractor.extract_room_temperatures(start_date, end_date)\n",
    "    \n",
    "    print(\"Loading heating relay data...\")\n",
    "    relay_data = await extractor.extract_relay_states(start_date, end_date)\n",
    "    \n",
    "    print(\"Loading battery data...\")\n",
    "    try:\n",
    "        battery_data = await extractor.extract_battery_data(start_date, end_date)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load battery data: {e}\")\n",
    "        battery_data = pd.DataFrame()\n",
    "    \n",
    "    return weather_data, current_weather, pv_data, consumption_data, room_data, relay_data, battery_data\n",
    "\n",
    "# Load data\n",
    "weather_data, current_weather, pv_data, consumption_data, room_data, relay_data, battery_data = await load_weather_and_energy_data()\n",
    "\n",
    "print(f\"\\nData loaded:\")\n",
    "print(f\"  Weather forecast records: {len(weather_data)}\")\n",
    "print(f\"  Current weather records: {len(current_weather)}\")\n",
    "print(f\"  PV records: {len(pv_data)}\")\n",
    "print(f\"  Consumption records: {len(consumption_data)}\")\n",
    "print(f\"  Room data: {len(room_data)} rooms\")\n",
    "print(f\"  Relay data: {len(relay_data)} rooms\")\n",
    "print(f\"  Battery records: {len(battery_data)}\")\n",
    "\n",
    "# Display available weather parameters\n",
    "if not weather_data.empty:\n",
    "    print(f\"\\nWeather forecast parameters: {list(weather_data.columns)}\")\nif not current_weather.empty:\n    print(f\"Current weather parameters: {list(current_weather.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge and Prepare Weather Data\n",
    "\n",
    "Combine different weather data sources and prepare for correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge weather data sources\n",
    "merged_weather = pd.DataFrame()\n",
    "\n",
    "if not weather_data.empty:\n",
    "    merged_weather = weather_data.copy()\n",
    "    print(f\"Using weather forecast data as primary source: {len(merged_weather)} records\")\n",
    "\n",
    "if not current_weather.empty:\n",
    "    if merged_weather.empty:\n",
    "        merged_weather = current_weather.copy()\n",
    "        print(f\"Using current weather data as primary source: {len(merged_weather)} records\")\n",
    "    else:\n",
    "        # Merge current weather with forecast data\n",
    "        common_cols = set(merged_weather.columns) & set(current_weather.columns)\n",
    "        \n",
    "        # Prioritize current weather for overlapping periods\n",
    "        for col in common_cols:\n",
    "            if col in current_weather.columns:\n",
    "                # Fill missing values in forecast with current weather\n",
    "                merged_weather[col] = merged_weather[col].fillna(current_weather[col])\n",
    "        \n",
    "        # Add unique columns from current weather\n",
    "        unique_current_cols = set(current_weather.columns) - common_cols\n",
    "        for col in unique_current_cols:\n",
    "            merged_weather[col] = current_weather[col]\n",
    "        \n",
    "        print(f\"Merged weather data: {len(merged_weather)} records with {len(merged_weather.columns)} parameters\")\n",
    "\n",
    "if merged_weather.empty:\n",
    "    print(\"Error: No weather data available for analysis\")\nelse:\n",
    "    # Resample weather data to hourly intervals\n",
    "    weather_hourly = merged_weather.resample('H').mean()\n",
    "    \n",
    "    # Add derived weather features\n",
    "    if 'temperature_2m' in weather_hourly.columns:\n",
    "        # Temperature features\n",
    "        weather_hourly['temp_celsius'] = weather_hourly['temperature_2m']\n",
    "        weather_hourly['heating_degree_hours'] = np.maximum(18 - weather_hourly['temp_celsius'], 0)  # HDD base 18°C\n",
    "        weather_hourly['cooling_degree_hours'] = np.maximum(weather_hourly['temp_celsius'] - 24, 0)  # CDD base 24°C\n",
    "    \n",
    "    if 'shortwave_radiation' in weather_hourly.columns:\n",
    "        # Solar radiation features\n",
    "        weather_hourly['solar_irradiance'] = weather_hourly['shortwave_radiation']\n",
    "        weather_hourly['solar_energy_wh_m2'] = weather_hourly['solar_irradiance']  # Wh/m² per hour\n",
    "    \n",
    "    if 'cloudcover' in weather_hourly.columns:\n",
    "        # Cloud features\n",
    "        weather_hourly['cloud_factor'] = (100 - weather_hourly['cloudcover']) / 100  # Clear sky factor\n",
    "    \n",
    "    if 'windspeed_10m' in weather_hourly.columns:\n",
    "        # Wind features\n",
    "        weather_hourly['wind_chill_factor'] = np.where(\n",
    "            weather_hourly['windspeed_10m'] > 5,\n",
    "            13.12 + 0.6215 * weather_hourly.get('temp_celsius', 20) - \n",
    "            11.37 * (weather_hourly['windspeed_10m'] ** 0.16) +\n",
    "            0.3965 * weather_hourly.get('temp_celsius', 20) * (weather_hourly['windspeed_10m'] ** 0.16),\n",
    "            weather_hourly.get('temp_celsius', 20)\n",
    "        )\n",
    "    \n",
    "    # Add time-based features\n",
    "    weather_hourly['hour'] = weather_hourly.index.hour\n",
    "    weather_hourly['day_of_year'] = weather_hourly.index.dayofyear\n",
    "    weather_hourly['month'] = weather_hourly.index.month\n",
    "    weather_hourly['is_daylight'] = (weather_hourly['hour'] >= 6) & (weather_hourly['hour'] <= 20)\n",
    "    \n",
    "    print(f\"\\nProcessed weather data: {len(weather_hourly)} hours\")\n",
    "    print(f\"Available weather features: {len(weather_hourly.columns)}\")\n",
    "    print(f\"Sample features: {list(weather_hourly.columns)[:10]}\")\n    \n    # Data quality check\n    missing_pct = weather_hourly.isnull().mean() * 100\n    high_missing = missing_pct[missing_pct > 20]\n    \n    if len(high_missing) > 0:\n        print(f\"\\nWeather parameters with >20% missing data:\")\n        for param, pct in high_missing.items():\n            print(f\"  {param}: {pct:.1f}% missing\")\n    else:\n        print(f\"\\nWeather data quality: Good (all parameters <20% missing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PV Production vs Weather Correlation\n",
    "\n",
    "Analyze correlation between solar production and weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze PV production vs weather correlation\nif not pv_data.empty and not weather_hourly.empty:\n    \n    # Prepare PV data\n    pv_hourly = pv_data.resample('H').mean()\n    \n    # Merge PV and weather data\n    pv_weather = pd.merge(pv_hourly, weather_hourly, left_index=True, right_index=True, how='inner')\n    \n    if len(pv_weather) > 24:  # Need sufficient data\n        print(f\"\\nPV-Weather Correlation Analysis:\")\n        print(f\"Merged dataset: {len(pv_weather)} hours\")\n        \n        # Focus on daylight hours for solar analysis\n        daylight_data = pv_weather[pv_weather['is_daylight']].copy()\n        \n        if len(daylight_data) > 10:\n            # Define PV power column\n            pv_power_col = 'InputPower' if 'InputPower' in daylight_data.columns else None\n            if not pv_power_col and 'solar_power' in daylight_data.columns:\n                pv_power_col = 'solar_power'\n            \n            if pv_power_col:\n                # Calculate correlations with weather parameters\n                weather_params = ['temperature_2m', 'shortwave_radiation', 'direct_radiation', \n                                 'diffuse_radiation', 'cloudcover', 'humidity']\n                available_params = [p for p in weather_params if p in daylight_data.columns]\n                \n                pv_weather_correlations = {}\n                \n                for param in available_params:\n                    correlation = daylight_data[pv_power_col].corr(daylight_data[param])\n                    pv_weather_correlations[param] = correlation\n                \n                # Display correlations\n                print(f\"\\nPV Power Correlations (daylight hours only):\")\n                print(\"=\" * 50)\n                sorted_corrs = sorted(pv_weather_correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n                \n                for param, corr in sorted_corrs:\n                    print(f\"{param:25s}: {corr:+.3f}\")\n                \n                # Analyze solar radiation relationship\n                if 'shortwave_radiation' in daylight_data.columns:\n                    # Filter for meaningful production periods\n                    production_data = daylight_data[daylight_data[pv_power_col] > 100].copy()\n                    \n                    if len(production_data) > 20:\n                        # Calculate PV efficiency (power per unit radiation)\n                        production_data['pv_efficiency'] = production_data[pv_power_col] / (production_data['shortwave_radiation'] + 1)\n                        \n                        # Analyze efficiency vs temperature\n                        if 'temperature_2m' in production_data.columns:\n                            temp_bins = pd.cut(production_data['temperature_2m'], bins=10)\n                            efficiency_by_temp = production_data.groupby(temp_bins)['pv_efficiency'].agg(['mean', 'count'])\n                            \n                            # Only consider bins with sufficient data\n                            valid_bins = efficiency_by_temp[efficiency_by_temp['count'] >= 5]\n                            \n                            if len(valid_bins) >= 3:\n                                # Find optimal temperature\n                                optimal_temp_bin = valid_bins['mean'].idxmax()\n                                optimal_temp = optimal_temp_bin.mid\n                                max_efficiency = valid_bins['mean'].max()\n                                \n                                print(f\"\\nPV Efficiency Analysis:\")\n                                print(f\"Optimal temperature: {optimal_temp:.1f}°C\")\n                                print(f\"Maximum efficiency: {max_efficiency:.3f} W per W/m²\")\n                                \n                                # Calculate temperature coefficient\n                                temp_values = [interval.mid for interval in valid_bins.index]\n                                eff_values = valid_bins['mean'].values\n                                \n                                if len(temp_values) >= 3:\n                                    # Fit linear relationship\n                                    slope, intercept, r_value, p_value, std_err = stats.linregress(temp_values, eff_values)\n                                    \n                                    print(f\"Temperature coefficient: {slope:.6f} per °C\")\n                                    print(f\"R-squared: {r_value**2:.3f}\")\n                        \n                        # Analyze cloud cover impact\n                        if 'cloudcover' in production_data.columns:\n                            cloud_bins = pd.cut(production_data['cloudcover'], bins=[0, 25, 50, 75, 100], \n                                               labels=['Clear', 'Partly Cloudy', 'Mostly Cloudy', 'Overcast'])\n                            \n                            cloud_impact = production_data.groupby(cloud_bins)[pv_power_col].agg(['mean', 'std', 'count'])\n                            \n                            print(f\"\\nCloud Cover Impact on PV Production:\")\n                            print(\"-\" * 45)\n                            print(f\"{'Condition':15s} {'Avg Power (W)':12s} {'Std (W)':10s} {'Count':8s}\")\n                            print(\"-\" * 45)\n                            \n                            for condition, row in cloud_impact.iterrows():\n                                if row['count'] >= 5:  # Only show conditions with sufficient data\n                                    print(f\"{condition:15s} {row['mean']:11.0f} {row['std']:9.0f} {row['count']:7.0f}\")\n                \n                # Store PV weather analysis results\n                pv_weather_analysis = {\n                    'correlations': pv_weather_correlations,\n                    'daylight_hours_analyzed': len(daylight_data),\n                    'production_hours': len(production_data) if 'production_data' in locals() else 0\n                }\n                \n                if 'efficiency_by_temp' in locals():\n                    pv_weather_analysis['temperature_analysis'] = {\n                        'optimal_temp': optimal_temp if 'optimal_temp' in locals() else None,\n                        'max_efficiency': max_efficiency if 'max_efficiency' in locals() else None,\n                        'temp_coefficient': slope if 'slope' in locals() else None\n                    }\n                \n                if 'cloud_impact' in locals():\n                    pv_weather_analysis['cloud_impact'] = cloud_impact.to_dict()\n            \n            else:\n                print(\"No PV power data available for correlation analysis\")\n                pv_weather_analysis = {}\n        else:\n            print(\"Insufficient daylight data for PV analysis\")\n            pv_weather_analysis = {}\n    else:\n        print(\"Insufficient merged PV-weather data\")\n        pv_weather_analysis = {}\nelse:\n    print(\"PV or weather data not available\")\n    pv_weather_analysis = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PV-weather relationships\nif pv_weather_analysis and 'correlations' in pv_weather_analysis:\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # Correlation heatmap\n    if len(pv_weather_analysis['correlations']) > 0:\n        corr_data = pd.Series(pv_weather_analysis['correlations'])\n        corr_data.plot(kind='barh', ax=axes[0,0], color='skyblue')\n        axes[0,0].set_title('PV Power - Weather Correlations')\n        axes[0,0].set_xlabel('Correlation Coefficient')\n        axes[0,0].grid(True, alpha=0.3)\n        axes[0,0].axvline(x=0, color='black', linewidth=0.5)\n    \n    # PV vs Solar Radiation scatter\n    if 'shortwave_radiation' in daylight_data.columns and pv_power_col:\n        sample_size = min(500, len(daylight_data))\n        sample_data = daylight_data.sample(sample_size)\n        \n        scatter = axes[0,1].scatter(sample_data['shortwave_radiation'], sample_data[pv_power_col],\n                                   c=sample_data.get('temperature_2m', 20), cmap='viridis', alpha=0.6)\n        axes[0,1].set_xlabel('Solar Radiation (W/m²)')\n        axes[0,1].set_ylabel('PV Power (W)')\n        axes[0,1].set_title('PV Power vs Solar Radiation')\n        axes[0,1].grid(True, alpha=0.3)\n        \n        # Add colorbar for temperature\n        if 'temperature_2m' in sample_data.columns:\n            cbar = plt.colorbar(scatter, ax=axes[0,1])\n            cbar.set_label('Temperature (°C)')\n    \n    # Temperature efficiency curve\n    if 'temperature_analysis' in pv_weather_analysis and 'efficiency_by_temp' in locals():\n        valid_bins = efficiency_by_temp[efficiency_by_temp['count'] >= 5]\n        if len(valid_bins) > 0:\n            x_temps = [interval.mid for interval in valid_bins.index]\n            y_effs = valid_bins['mean'].values\n            \n            axes[1,0].plot(x_temps, y_effs, 'o-', linewidth=2, markersize=6)\n            axes[1,0].set_xlabel('Temperature (°C)')\n            axes[1,0].set_ylabel('PV Efficiency (W per W/m²)')\n            axes[1,0].set_title('PV Efficiency vs Temperature')\n            axes[1,0].grid(True, alpha=0.3)\n            \n            # Add trend line if enough points\n            if len(x_temps) >= 3:\n                z = np.polyfit(x_temps, y_effs, 1)\n                p = np.poly1d(z)\n                axes[1,0].plot(x_temps, p(x_temps), 'r--', alpha=0.8, label=f'Trend: {z[0]:.6f}/°C')\n                axes[1,0].legend()\n    \n    # Cloud cover impact\n    if 'cloud_impact' in pv_weather_analysis and 'cloud_impact' in locals():\n        cloud_means = cloud_impact['mean']\n        cloud_stds = cloud_impact['std']\n        \n        bars = axes[1,1].bar(range(len(cloud_means)), cloud_means.values, \n                            yerr=cloud_stds.values, capsize=5, alpha=0.8)\n        axes[1,1].set_xticks(range(len(cloud_means)))\n        axes[1,1].set_xticklabels(cloud_means.index, rotation=45)\n        axes[1,1].set_ylabel('Average PV Power (W)')\n        axes[1,1].set_title('PV Production by Cloud Condition')\n        axes[1,1].grid(True, alpha=0.3)\n        \n        # Add value labels on bars\n        for i, (bar, mean_val) in enumerate(zip(bars, cloud_means.values)):\n            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + cloud_stds.iloc[i]/2,\n                          f'{mean_val:.0f}W', ha='center', va='bottom', fontsize=9)\n    \n    plt.tight_layout()\n    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Heating Demand vs Weather Correlation\n",
    "\n",
    "Analyze relationship between outdoor conditions and heating system usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze heating demand vs weather correlation\nif relay_data and not weather_hourly.empty:\n    \n    # Calculate total heating demand from all rooms\n    total_heating_power = pd.Series(0, index=weather_hourly.index)\n    \n    # Room power ratings for heating load calculation\n    room_power_ratings = {\n        'obyvacka': 2000, 'kuchyn': 1500, 'loznice': 1500,\n        'detsky_pokoj': 1000, 'koupelna': 800, 'pracovna': 1200,\n        'chodba': 500, 'spiz': 300\n    }\n    \n    rooms_with_heating = []\n    \n    for room, relay_df in relay_data.items():\n        if not relay_df.empty and 'value' in relay_df.columns:\n            # Resample relay data to hourly\n            relay_hourly = relay_df['value'].resample('H').mean()\n            \n            # Calculate heating power for this room\n            room_power = room_power_ratings.get(room, 1000)\n            heating_power = relay_hourly * room_power\n            \n            # Add to total heating\n            total_heating_power = total_heating_power.add(heating_power, fill_value=0)\n            rooms_with_heating.append(room)\n    \n    if len(rooms_with_heating) > 0:\n        # Merge heating and weather data\n        heating_weather = pd.merge(total_heating_power.to_frame('heating_power'), \n                                  weather_hourly, left_index=True, right_index=True, how='inner')\n        \n        print(f\"\\nHeating-Weather Correlation Analysis:\")\n        print(f\"Rooms included: {', '.join(rooms_with_heating)}\")\n        print(f\"Merged dataset: {len(heating_weather)} hours\")\n        \n        # Calculate correlations with weather parameters\n        weather_params = ['temperature_2m', 'humidity', 'windspeed_10m', 'cloudcover', \n                         'heating_degree_hours', 'wind_chill_factor']\n        available_params = [p for p in weather_params if p in heating_weather.columns]\n        \n        heating_weather_correlations = {}\n        \n        for param in available_params:\n            correlation = heating_weather['heating_power'].corr(heating_weather[param])\n            heating_weather_correlations[param] = correlation\n        \n        # Display correlations\n        print(f\"\\nHeating Power Correlations:\")\n        print(\"=\" * 40)\n        sorted_corrs = sorted(heating_weather_correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n        \n        for param, corr in sorted_corrs:\n            print(f\"{param:25s}: {corr:+.3f}\")\n        \n        # Analyze temperature-heating relationship\n        if 'temperature_2m' in heating_weather.columns:\n            # Find heating threshold temperature\n            temp_bins = pd.cut(heating_weather['temperature_2m'], bins=20)\n            heating_by_temp = heating_weather.groupby(temp_bins)['heating_power'].agg(['mean', 'count'])\n            \n            # Only consider bins with sufficient data\n            valid_bins = heating_by_temp[heating_by_temp['count'] >= 5]\n            \n            if len(valid_bins) >= 5:\n                # Find temperature where heating starts\n                heating_threshold = None\n                min_heating_temp = None\n                \n                for temp_bin, row in valid_bins.iterrows():\n                    if row['mean'] > heating_weather['heating_power'].mean() * 0.1:  # 10% of average\n                        heating_threshold = temp_bin.right\n                        break\n                \n                # Find minimum heating temperature\n                non_zero_heating = valid_bins[valid_bins['mean'] > 100]  # At least 100W\n                if len(non_zero_heating) > 0:\n                    min_heating_temp = max([interval.right for interval in non_zero_heating.index])\n                \n                print(f\"\\nHeating Temperature Analysis:\")\n                if heating_threshold:\n                    print(f\"Heating threshold: {heating_threshold:.1f}°C\")\n                if min_heating_temp:\n                    print(f\"Minimum heating temperature: {min_heating_temp:.1f}°C\")\n                \n                # Calculate heating degree day relationship\n                if 'heating_degree_hours' in heating_weather.columns:\n                    # Fit linear model: heating power vs HDD\n                    hdd_data = heating_weather[heating_weather['heating_degree_hours'] > 0]\n                    \n                    if len(hdd_data) > 10:\n                        X = hdd_data['heating_degree_hours'].values.reshape(-1, 1)\n                        y = hdd_data['heating_power'].values\n                        \n                        model = LinearRegression().fit(X, y)\n                        hdd_coefficient = model.coef_[0]\n                        hdd_r2 = model.score(X, y)\n                        \n                        print(f\"Heating degree relationship:\")\n                        print(f\"  Coefficient: {hdd_coefficient:.1f} W per degree-hour\")\n                        print(f\"  R-squared: {hdd_r2:.3f}\")\n        \n        # Analyze seasonal heating patterns\n        heating_weather['month'] = heating_weather.index.month\n        monthly_heating = heating_weather.groupby('month')['heating_power'].agg(['mean', 'sum', 'count'])\n        \n        print(f\"\\nMonthly Heating Pattern:\")\n        print(\"-\" * 40)\n        print(f\"{'Month':8s} {'Avg (W)':10s} {'Total (kWh)':12s} {'Hours':8s}\")\n        print(\"-\" * 40)\n        \n        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n                      'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n        \n        for month, row in monthly_heating.iterrows():\n            if row['count'] > 0:\n                month_name = month_names[month - 1]\n                total_kwh = row['sum'] / 1000  # Convert Wh to kWh\n                print(f\"{month_name:8s} {row['mean']:9.0f} {total_kwh:11.1f} {row['count']:7.0f}\")\n        \n        # Store heating weather analysis\n        heating_weather_analysis = {\n            'correlations': heating_weather_correlations,\n            'rooms_analyzed': rooms_with_heating,\n            'hours_analyzed': len(heating_weather),\n            'monthly_pattern': monthly_heating.to_dict()\n        }\n        \n        if 'heating_threshold' in locals():\n            heating_weather_analysis['temperature_analysis'] = {\n                'heating_threshold': heating_threshold,\n                'min_heating_temp': min_heating_temp if 'min_heating_temp' in locals() else None\n            }\n        \n        if 'hdd_coefficient' in locals():\n            heating_weather_analysis['hdd_analysis'] = {\n                'coefficient': hdd_coefficient,\n                'r_squared': hdd_r2\n            }\n    \n    else:\n        print(\"No heating relay data available\")\n        heating_weather_analysis = {}\nelse:\n    print(\"Heating or weather data not available\")\n    heating_weather_analysis = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize heating-weather relationships\nif heating_weather_analysis and 'correlations' in heating_weather_analysis:\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # Heating correlation bar chart\n    if len(heating_weather_analysis['correlations']) > 0:\n        corr_data = pd.Series(heating_weather_analysis['correlations'])\n        bars = corr_data.plot(kind='barh', ax=axes[0,0], color='lightcoral')\n        axes[0,0].set_title('Heating Power - Weather Correlations')\n        axes[0,0].set_xlabel('Correlation Coefficient')\n        axes[0,0].grid(True, alpha=0.3)\n        axes[0,0].axvline(x=0, color='black', linewidth=0.5)\n    \n    # Heating vs Temperature scatter\n    if 'temperature_2m' in heating_weather.columns:\n        sample_size = min(1000, len(heating_weather))\n        sample_data = heating_weather.sample(sample_size)\n        \n        # Color by hour to show daily patterns\n        scatter = axes[0,1].scatter(sample_data['temperature_2m'], sample_data['heating_power'],\n                                   c=sample_data.index.hour, cmap='tab20', alpha=0.6, s=20)\n        axes[0,1].set_xlabel('Temperature (°C)')\n        axes[0,1].set_ylabel('Heating Power (W)')\n        axes[0,1].set_title('Heating Power vs Temperature')\n        axes[0,1].grid(True, alpha=0.3)\n        \n        # Add colorbar for hour\n        cbar = plt.colorbar(scatter, ax=axes[0,1])\n        cbar.set_label('Hour of Day')\n        \n        # Add trend line\n        if len(sample_data) > 10:\n            z = np.polyfit(sample_data['temperature_2m'], sample_data['heating_power'], 1)\n            p = np.poly1d(z)\n            temp_range = np.linspace(sample_data['temperature_2m'].min(), \n                                   sample_data['temperature_2m'].max(), 100)\n            axes[0,1].plot(temp_range, p(temp_range), 'r-', linewidth=2, alpha=0.8)\n    \n    # Temperature binned heating\n    if 'valid_bins' in locals() and len(valid_bins) > 0:\n        x_temps = [interval.mid for interval in valid_bins.index]\n        y_heating = valid_bins['mean'].values\n        \n        axes[1,0].plot(x_temps, y_heating, 'o-', linewidth=2, markersize=6, color='red')\n        axes[1,0].set_xlabel('Temperature (°C)')\n        axes[1,0].set_ylabel('Average Heating Power (W)')\n        axes[1,0].set_title('Heating Power vs Temperature (Binned)')\n        axes[1,0].grid(True, alpha=0.3)\n        \n        # Highlight heating threshold\n        if 'heating_threshold' in locals() and heating_threshold:\n            axes[1,0].axvline(x=heating_threshold, color='orange', linestyle='--', \n                             label=f'Threshold: {heating_threshold:.1f}°C')\n            axes[1,0].legend()\n    \n    # Monthly heating pattern\n    if 'monthly_pattern' in heating_weather_analysis:\n        monthly_data = pd.DataFrame(heating_weather_analysis['monthly_pattern'])\n        if not monthly_data.empty and 'mean' in monthly_data.columns:\n            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n            \n            # Filter months with data\n            available_months = [m for m in monthly_data.index if m <= 12]\n            month_labels = [month_names[m-1] for m in available_months]\n            month_values = [monthly_data.loc[m, 'mean'] for m in available_months]\n            \n            bars = axes[1,1].bar(month_labels, month_values, color='lightblue', alpha=0.8)\n            axes[1,1].set_ylabel('Average Heating Power (W)')\n            axes[1,1].set_title('Monthly Heating Demand')\n            axes[1,1].set_xticklabels(month_labels, rotation=45)\n            axes[1,1].grid(True, alpha=0.3)\n            \n            # Add value labels\n            for bar, value in zip(bars, month_values):\n                axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + value*0.01,\n                              f'{value:.0f}', ha='center', va='bottom', fontsize=9)\n    \n    plt.tight_layout()\n    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Total Energy Consumption vs Weather\n",
    "\n",
    "Analyze correlation between weather and total building energy consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze total consumption vs weather correlation\nif not consumption_data.empty and not weather_hourly.empty:\n    \n    # Prepare consumption data\n    consumption_hourly = consumption_data.resample('H').mean()\n    \n    # Find total power column\n    power_columns = [col for col in consumption_hourly.columns if 'power' in col.lower()]\n    if power_columns:\n        total_power_col = power_columns[0]\n    elif not pv_data.empty and 'ACPowerToUser' in pv_data.columns:\n        # Use PV self-consumption as proxy for total consumption\n        pv_hourly = pv_data['ACPowerToUser'].resample('H').mean()\n        consumption_hourly = pd.merge(consumption_hourly, pv_hourly.to_frame('total_power'),\n                                    left_index=True, right_index=True, how='outer')\n        total_power_col = 'total_power'\n    else:\n        total_power_col = None\n    \n    if total_power_col and total_power_col in consumption_hourly.columns:\n        # Merge consumption and weather data\n        consumption_weather = pd.merge(consumption_hourly[[total_power_col]], \n                                     weather_hourly, left_index=True, right_index=True, how='inner')\n        \n        print(f\"\\nTotal Consumption-Weather Correlation Analysis:\")\n        print(f\"Merged dataset: {len(consumption_weather)} hours\")\n        \n        # Calculate correlations with weather parameters\n        weather_params = ['temperature_2m', 'humidity', 'windspeed_10m', 'cloudcover',\n                         'shortwave_radiation', 'heating_degree_hours', 'cooling_degree_hours']\n        available_params = [p for p in weather_params if p in consumption_weather.columns]\n        \n        consumption_weather_correlations = {}\n        \n        for param in available_params:\n            correlation = consumption_weather[total_power_col].corr(consumption_weather[param])\n            consumption_weather_correlations[param] = correlation\n        \n        # Display correlations\n        print(f\"\\nTotal Consumption Correlations:\")\n        print(\"=\" * 45)\n        sorted_corrs = sorted(consumption_weather_correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n        \n        for param, corr in sorted_corrs:\n            print(f\"{param:25s}: {corr:+.3f}\")\n        \n        # Analyze consumption patterns by weather conditions\n        \n        # Temperature impact\n        if 'temperature_2m' in consumption_weather.columns:\n            temp_bins = pd.cut(consumption_weather['temperature_2m'], \n                              bins=[-20, 0, 5, 10, 15, 20, 25, 30, 35, 50], \n                              labels=['<0°C', '0-5°C', '5-10°C', '10-15°C', '15-20°C', \n                                     '20-25°C', '25-30°C', '30-35°C', '>35°C'])\n            \n            consumption_by_temp = consumption_weather.groupby(temp_bins)[total_power_col].agg(['mean', 'std', 'count'])\n            \n            # Only show bins with sufficient data\n            valid_temp_bins = consumption_by_temp[consumption_by_temp['count'] >= 10]\n            \n            if len(valid_temp_bins) > 0:\n                print(f\"\\nConsumption by Temperature Range:\")\n                print(\"-\" * 50)\n                print(f\"{'Range':12s} {'Avg (W)':10s} {'Std (W)':10s} {'Count':8s}\")\n                print(\"-\" * 50)\n                \n                for temp_range, row in valid_temp_bins.iterrows():\n                    print(f\"{temp_range:12s} {row['mean']:9.0f} {row['std']:9.0f} {row['count']:7.0f}\")\n        \n        # Solar radiation impact\n        if 'shortwave_radiation' in consumption_weather.columns:\n            # Separate day and night analysis\n            day_data = consumption_weather[consumption_weather['is_daylight']]\n            night_data = consumption_weather[~consumption_weather['is_daylight']]\n            \n            if len(day_data) > 10 and len(night_data) > 10:\n                day_corr = day_data[total_power_col].corr(day_data['shortwave_radiation'])\n                night_avg = night_data[total_power_col].mean()\n                day_avg = day_data[total_power_col].mean()\n                \n                print(f\"\\nDay/Night Consumption Analysis:\")\n                print(f\"Day-time average: {day_avg:.0f} W\")\n                print(f\"Night-time average: {night_avg:.0f} W\")\n                print(f\"Day/night ratio: {day_avg/night_avg:.2f}\")\n                print(f\"Solar correlation (daytime): {day_corr:.3f}\")\n        \n        # Seasonal consumption analysis\n        consumption_weather['season'] = consumption_weather['month'].map({\n            12: 'Winter', 1: 'Winter', 2: 'Winter',\n            3: 'Spring', 4: 'Spring', 5: 'Spring',\n            6: 'Summer', 7: 'Summer', 8: 'Summer',\n            9: 'Autumn', 10: 'Autumn', 11: 'Autumn'\n        })\n        \n        seasonal_consumption = consumption_weather.groupby('season')[total_power_col].agg(['mean', 'std', 'count'])\n        \n        print(f\"\\nSeasonal Consumption Pattern:\")\n        print(\"-\" * 40)\n        print(f\"{'Season':10s} {'Avg (W)':10s} {'Std (W)':10s} {'Count':8s}\")\n        print(\"-\" * 40)\n        \n        for season, row in seasonal_consumption.iterrows():\n            if row['count'] > 0:\n                print(f\"{season:10s} {row['mean']:9.0f} {row['std']:9.0f} {row['count']:7.0f}\")\n        \n        # Weather extremes analysis\n        if 'temperature_2m' in consumption_weather.columns:\n            # Define extreme conditions\n            temp_95 = consumption_weather['temperature_2m'].quantile(0.95)\n            temp_5 = consumption_weather['temperature_2m'].quantile(0.05)\n            \n            hot_days = consumption_weather[consumption_weather['temperature_2m'] >= temp_95]\n            cold_days = consumption_weather[consumption_weather['temperature_2m'] <= temp_5]\n            normal_days = consumption_weather[\n                (consumption_weather['temperature_2m'] > temp_5) & \n                (consumption_weather['temperature_2m'] < temp_95)\n            ]\n            \n            if len(hot_days) > 5 and len(cold_days) > 5:\n                print(f\"\\nExtreme Weather Impact:\")\n                print(f\"Hot days (>{temp_95:.1f}°C): {hot_days[total_power_col].mean():.0f}W avg ({len(hot_days)} hours)\")\n                print(f\"Cold days (<{temp_5:.1f}°C): {cold_days[total_power_col].mean():.0f}W avg ({len(cold_days)} hours)\")\n                print(f\"Normal days: {normal_days[total_power_col].mean():.0f}W avg ({len(normal_days)} hours)\")\n        \n        # Store consumption weather analysis\n        consumption_weather_analysis = {\n            'correlations': consumption_weather_correlations,\n            'hours_analyzed': len(consumption_weather),\n            'seasonal_pattern': seasonal_consumption.to_dict()\n        }\n        \n        if 'day_avg' in locals():\n            consumption_weather_analysis['day_night_analysis'] = {\n                'day_average': day_avg,\n                'night_average': night_avg,\n                'day_night_ratio': day_avg/night_avg,\n                'solar_correlation_day': day_corr\n            }\n        \n        if 'hot_days' in locals():\n            consumption_weather_analysis['extreme_weather'] = {\n                'hot_threshold': temp_95,\n                'cold_threshold': temp_5,\n                'hot_consumption': hot_days[total_power_col].mean(),\n                'cold_consumption': cold_days[total_power_col].mean(),\n                'normal_consumption': normal_days[total_power_col].mean()\n            }\n    \n    else:\n        print(\"No suitable total power consumption data found\")\n        consumption_weather_analysis = {}\nelse:\n    print(\"Consumption or weather data not available\")\n    consumption_weather_analysis = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Weather-Based Prediction Models\n",
    "\n",
    "Develop models to predict energy parameters based on weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop weather-based prediction models\nweather_prediction_models = {}\n\n# Model 1: PV Production Prediction\nif pv_weather_analysis and 'daylight_data' in locals():\n    if len(daylight_data) > 50 and pv_power_col in daylight_data.columns:\n        print(\"\\nDeveloping PV Production Prediction Model:\")\n        print(\"=\" * 50)\n        \n        # Prepare features\n        pv_features = ['shortwave_radiation', 'direct_radiation', 'diffuse_radiation', \n                      'temperature_2m', 'cloudcover', 'humidity']\n        available_pv_features = [f for f in pv_features if f in daylight_data.columns]\n        \n        if len(available_pv_features) >= 2:\n            # Filter out zero/very low radiation periods\n            pv_model_data = daylight_data[daylight_data.get('shortwave_radiation', 0) > 50].copy()\n            \n            if len(pv_model_data) > 30:\n                X_pv = pv_model_data[available_pv_features].dropna()\n                y_pv = pv_model_data.loc[X_pv.index, pv_power_col]\n                \n                # Split data\n                X_pv_train, X_pv_test, y_pv_train, y_pv_test = train_test_split(\n                    X_pv, y_pv, test_size=0.3, random_state=42)\n                \n                # Scale features\n                scaler_pv = StandardScaler()\n                X_pv_train_scaled = scaler_pv.fit_transform(X_pv_train)\n                X_pv_test_scaled = scaler_pv.transform(X_pv_test)\n                \n                # Train models\n                pv_models = {\n                    'Linear': LinearRegression(),\n                    'Ridge': Ridge(alpha=1.0),\n                    'Random Forest': RandomForestRegressor(n_estimators=50, random_state=42)\n                }\n                \n                pv_model_results = {}\n                \n                for name, model in pv_models.items():\n                    if name == 'Random Forest':\n                        model.fit(X_pv_train, y_pv_train)\n                        y_pred = model.predict(X_pv_test)\n                    else:\n                        model.fit(X_pv_train_scaled, y_pv_train)\n                        y_pred = model.predict(X_pv_test_scaled)\n                    \n                    mae = mean_absolute_error(y_pv_test, y_pred)\n                    rmse = np.sqrt(mean_squared_error(y_pv_test, y_pred))\n                    r2 = r2_score(y_pv_test, y_pred)\n                    \n                    pv_model_results[name] = {'mae': mae, 'rmse': rmse, 'r2': r2}\n                \n                # Display results\n                print(f\"Training samples: {len(X_pv_train)}\")\n                print(f\"Test samples: {len(X_pv_test)}\")\n                print(f\"Features used: {', '.join(available_pv_features)}\")\n                print(f\"\\nModel Performance:\")\n                print(f\"{'Model':15s} {'MAE (W)':10s} {'RMSE (W)':10s} {'R²':8s}\")\n                print(\"-\" * 45)\n                \n                for name, results in pv_model_results.items():\n                    print(f\"{name:15s} {results['mae']:9.0f} {results['rmse']:9.0f} {results['r2']:7.3f}\")\n                \n                # Select best model\n                best_pv_model = max(pv_model_results.keys(), key=lambda x: pv_model_results[x]['r2'])\n                print(f\"\\nBest model: {best_pv_model}\")\n                \n                weather_prediction_models['pv_production'] = {\n                    'features': available_pv_features,\n                    'results': pv_model_results,\n                    'best_model': best_pv_model,\n                    'training_samples': len(X_pv_train)\n                }\n\n# Model 2: Heating Demand Prediction\nif heating_weather_analysis and 'heating_weather' in locals():\n    if len(heating_weather) > 50:\n        print(\"\\n\\nDeveloping Heating Demand Prediction Model:\")\n        print(\"=\" * 50)\n        \n        # Prepare features\n        heating_features = ['temperature_2m', 'windspeed_10m', 'humidity', \n                           'heating_degree_hours', 'wind_chill_factor']\n        available_heating_features = [f for f in heating_features if f in heating_weather.columns]\n        \n        if len(available_heating_features) >= 2:\n            # Filter out periods with very low heating\n            heating_model_data = heating_weather.copy()\n            \n            X_heat = heating_model_data[available_heating_features].dropna()\n            y_heat = heating_model_data.loc[X_heat.index, 'heating_power']\n            \n            if len(X_heat) > 30:\n                # Split data\n                X_heat_train, X_heat_test, y_heat_train, y_heat_test = train_test_split(\n                    X_heat, y_heat, test_size=0.3, random_state=42)\n                \n                # Scale features\n                scaler_heat = StandardScaler()\n                X_heat_train_scaled = scaler_heat.fit_transform(X_heat_train)\n                X_heat_test_scaled = scaler_heat.transform(X_heat_test)\n                \n                # Train models\n                heat_models = {\n                    'Linear': LinearRegression(),\n                    'Ridge': Ridge(alpha=1.0),\n                    'Random Forest': RandomForestRegressor(n_estimators=50, random_state=42)\n                }\n                \n                heat_model_results = {}\n                \n                for name, model in heat_models.items():\n                    if name == 'Random Forest':\n                        model.fit(X_heat_train, y_heat_train)\n                        y_pred = model.predict(X_heat_test)\n                    else:\n                        model.fit(X_heat_train_scaled, y_heat_train)\n                        y_pred = model.predict(X_heat_test_scaled)\n                    \n                    mae = mean_absolute_error(y_heat_test, y_pred)\n                    rmse = np.sqrt(mean_squared_error(y_heat_test, y_pred))\n                    r2 = r2_score(y_heat_test, y_pred)\n                    \n                    heat_model_results[name] = {'mae': mae, 'rmse': rmse, 'r2': r2}\n                \n                # Display results\n                print(f\"Training samples: {len(X_heat_train)}\")\n                print(f\"Test samples: {len(X_heat_test)}\")\n                print(f\"Features used: {', '.join(available_heating_features)}\")\n                print(f\"\\nModel Performance:\")\n                print(f\"{'Model':15s} {'MAE (W)':10s} {'RMSE (W)':10s} {'R²':8s}\")\n                print(\"-\" * 45)\n                \n                for name, results in heat_model_results.items():\n                    print(f\"{name:15s} {results['mae']:9.0f} {results['rmse']:9.0f} {results['r2']:7.3f}\")\n                \n                # Select best model\n                best_heat_model = max(heat_model_results.keys(), key=lambda x: heat_model_results[x]['r2'])\n                print(f\"\\nBest model: {best_heat_model}\")\n                \n                weather_prediction_models['heating_demand'] = {\n                    'features': available_heating_features,\n                    'results': heat_model_results,\n                    'best_model': best_heat_model,\n                    'training_samples': len(X_heat_train)\n                }\n\n# Model 3: Total Consumption Prediction\nif consumption_weather_analysis and 'consumption_weather' in locals():\n    if len(consumption_weather) > 50 and total_power_col:\n        print(\"\\n\\nDeveloping Total Consumption Prediction Model:\")\n        print(\"=\" * 50)\n        \n        # Prepare features\n        consumption_features = ['temperature_2m', 'shortwave_radiation', 'cloudcover', \n                               'humidity', 'heating_degree_hours', 'cooling_degree_hours']\n        available_consumption_features = [f for f in consumption_features if f in consumption_weather.columns]\n        \n        if len(available_consumption_features) >= 2:\n            X_cons = consumption_weather[available_consumption_features].dropna()\n            y_cons = consumption_weather.loc[X_cons.index, total_power_col]\n            \n            if len(X_cons) > 30:\n                # Split data\n                X_cons_train, X_cons_test, y_cons_train, y_cons_test = train_test_split(\n                    X_cons, y_cons, test_size=0.3, random_state=42)\n                \n                # Scale features\n                scaler_cons = StandardScaler()\n                X_cons_train_scaled = scaler_cons.fit_transform(X_cons_train)\n                X_cons_test_scaled = scaler_cons.transform(X_cons_test)\n                \n                # Train models\n                cons_models = {\n                    'Linear': LinearRegression(),\n                    'Ridge': Ridge(alpha=1.0),\n                    'Random Forest': RandomForestRegressor(n_estimators=50, random_state=42)\n                }\n                \n                cons_model_results = {}\n                \n                for name, model in cons_models.items():\n                    if name == 'Random Forest':\n                        model.fit(X_cons_train, y_cons_train)\n                        y_pred = model.predict(X_cons_test)\n                    else:\n                        model.fit(X_cons_train_scaled, y_cons_train)\n                        y_pred = model.predict(X_cons_test_scaled)\n                    \n                    mae = mean_absolute_error(y_cons_test, y_pred)\n                    rmse = np.sqrt(mean_squared_error(y_cons_test, y_pred))\n                    r2 = r2_score(y_cons_test, y_pred)\n                    \n                    cons_model_results[name] = {'mae': mae, 'rmse': rmse, 'r2': r2}\n                \n                # Display results\n                print(f\"Training samples: {len(X_cons_train)}\")\n                print(f\"Test samples: {len(X_cons_test)}\")\n                print(f\"Features used: {', '.join(available_consumption_features)}\")\n                print(f\"\\nModel Performance:\")\n                print(f\"{'Model':15s} {'MAE (W)':10s} {'RMSE (W)':10s} {'R²':8s}\")\n                print(\"-\" * 45)\n                \n                for name, results in cons_model_results.items():\n                    print(f\"{name:15s} {results['mae']:9.0f} {results['rmse']:9.0f} {results['r2']:7.3f}\")\n                \n                # Select best model\n                best_cons_model = max(cons_model_results.keys(), key=lambda x: cons_model_results[x]['r2'])\n                print(f\"\\nBest model: {best_cons_model}\")\n                \n                weather_prediction_models['total_consumption'] = {\n                    'features': available_consumption_features,\n                    'results': cons_model_results,\n                    'best_model': best_cons_model,\n                    'training_samples': len(X_cons_train)\n                }\n\nif not weather_prediction_models:\n    print(\"\\nInsufficient data for weather-based prediction models\")\nelse:\n    print(f\"\\n\\nWeather-based models developed: {list(weather_prediction_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extreme Weather Analysis\n",
    "\n",
    "Analyze system performance during extreme weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme weather event analysis\nif not weather_hourly.empty:\n    print(\"\\nExtreme Weather Event Analysis:\")\n    print(\"=\" * 50)\n    \n    extreme_weather_events = {}\n    \n    # Define extreme weather thresholds\n    if 'temperature_2m' in weather_hourly.columns:\n        temp_data = weather_hourly['temperature_2m'].dropna()\n        if len(temp_data) > 100:\n            # Temperature extremes\n            temp_p99 = temp_data.quantile(0.99)\n            temp_p1 = temp_data.quantile(0.01)\n            \n            hot_extreme = weather_hourly[weather_hourly['temperature_2m'] >= temp_p99]\n            cold_extreme = weather_hourly[weather_hourly['temperature_2m'] <= temp_p1]\n            \n            extreme_weather_events['hot_extreme'] = {\n                'threshold': temp_p99,\n                'hours': len(hot_extreme),\n                'dates': hot_extreme.index.date if len(hot_extreme) > 0 else []\n            }\n            \n            extreme_weather_events['cold_extreme'] = {\n                'threshold': temp_p1,\n                'hours': len(cold_extreme),\n                'dates': cold_extreme.index.date if len(cold_extreme) > 0 else []\n            }\n    \n    # Wind extremes\n    if 'windspeed_10m' in weather_hourly.columns:\n        wind_data = weather_hourly['windspeed_10m'].dropna()\n        if len(wind_data) > 100:\n            wind_p95 = wind_data.quantile(0.95)\n            high_wind = weather_hourly[weather_hourly['windspeed_10m'] >= wind_p95]\n            \n            extreme_weather_events['high_wind'] = {\n                'threshold': wind_p95,\n                'hours': len(high_wind),\n                'dates': high_wind.index.date if len(high_wind) > 0 else []\n            }\n    \n    # Solar radiation extremes\n    if 'shortwave_radiation' in weather_hourly.columns:\n        solar_data = weather_hourly['shortwave_radiation'].dropna()\n        if len(solar_data) > 100:\n            solar_p95 = solar_data.quantile(0.95)\n            solar_p5 = solar_data.quantile(0.05)\n            \n            high_solar = weather_hourly[weather_hourly['shortwave_radiation'] >= solar_p95]\n            low_solar = weather_hourly[weather_hourly['shortwave_radiation'] <= solar_p5]\n            \n            extreme_weather_events['high_solar'] = {\n                'threshold': solar_p95,\n                'hours': len(high_solar),\n                'dates': high_solar.index.date if len(high_solar) > 0 else []\n            }\n            \n            extreme_weather_events['low_solar'] = {\n                'threshold': solar_p5,\n                'hours': len(low_solar),\n                'dates': low_solar.index.date if len(low_solar) > 0 else []\n            }\n    \n    # Display extreme weather summary\n    print(f\"\\nExtreme Weather Event Summary:\")\n    print(\"-\" * 40)\n    \n    for event_type, data in extreme_weather_events.items():\n        threshold = data['threshold']\n        hours = data['hours']\n        unique_dates = len(set(data['dates'])) if data['dates'] else 0\n        \n        print(f\"{event_type:15s}: {threshold:6.1f} threshold, {hours:3d} hours, {unique_dates:2d} days\")\n    \n    # Analyze energy system performance during extremes\n    extreme_performance = {}\n    \n    # PV performance during extreme weather\n    if pv_weather_analysis and 'daylight_data' in locals():\n        print(f\"\\nPV Performance During Extreme Weather:\")\n        print(\"-\" * 45)\n        \n        normal_pv = daylight_data[pv_power_col].mean() if pv_power_col in daylight_data.columns else 0\n        \n        for event_type, data in extreme_weather_events.items():\n            if len(data['dates']) > 0:\n                # Find PV data during extreme events\n                extreme_dates = set(data['dates'])\n                extreme_pv_data = daylight_data[daylight_data.index.date.isin(extreme_dates)]\n                \n                if len(extreme_pv_data) > 0 and pv_power_col in extreme_pv_data.columns:\n                    extreme_pv_avg = extreme_pv_data[pv_power_col].mean()\n                    performance_ratio = extreme_pv_avg / normal_pv if normal_pv > 0 else 0\n                    \n                    print(f\"{event_type:15s}: {extreme_pv_avg:6.0f}W avg ({performance_ratio:5.1%} of normal)\")\n                    \n                    extreme_performance[f'pv_{event_type}'] = {\n                        'average_power': extreme_pv_avg,\n                        'performance_ratio': performance_ratio,\n                        'hours_analyzed': len(extreme_pv_data)\n                    }\n    \n    # Heating performance during extreme weather\n    if heating_weather_analysis and 'heating_weather' in locals():\n        print(f\"\\nHeating Performance During Extreme Weather:\")\n        print(\"-\" * 50)\n        \n        normal_heating = heating_weather['heating_power'].mean()\n        \n        for event_type, data in extreme_weather_events.items():\n            if len(data['dates']) > 0:\n                # Find heating data during extreme events\n                extreme_dates = set(data['dates'])\n                extreme_heating_data = heating_weather[heating_weather.index.date.isin(extreme_dates)]\n                \n                if len(extreme_heating_data) > 0:\n                    extreme_heating_avg = extreme_heating_data['heating_power'].mean()\n                    performance_ratio = extreme_heating_avg / normal_heating if normal_heating > 0 else 0\n                    \n                    print(f\"{event_type:15s}: {extreme_heating_avg:6.0f}W avg ({performance_ratio:5.1%} of normal)\")\n                    \n                    extreme_performance[f'heating_{event_type}'] = {\n                        'average_power': extreme_heating_avg,\n                        'performance_ratio': performance_ratio,\n                        'hours_analyzed': len(extreme_heating_data)\n                    }\n    \n    # Identify most impactful weather events\n    if extreme_performance:\n        print(f\"\\nMost Impactful Weather Events:\")\n        print(\"-\" * 35)\n        \n        # Sort by deviation from normal (absolute value)\n        impact_ranking = []\n        for event, perf in extreme_performance.items():\n            deviation = abs(perf['performance_ratio'] - 1.0)\n            impact_ranking.append((event, deviation, perf['performance_ratio']))\n        \n        impact_ranking.sort(key=lambda x: x[1], reverse=True)\n        \n        for event, deviation, ratio in impact_ranking[:5]:  # Top 5 most impactful\n            impact_desc = \"increase\" if ratio > 1 else \"decrease\"\n            print(f\"{event:20s}: {abs(ratio-1)*100:4.1f}% {impact_desc}\")\n    \n    # Store extreme weather analysis\n    extreme_weather_analysis = {\n        'events': extreme_weather_events,\n        'performance_impact': extreme_performance,\n        'analysis_period_hours': len(weather_hourly)\n    }\nelse:\n    print(\"No weather data available for extreme weather analysis\")\n    extreme_weather_analysis = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Weather Optimization Recommendations\n",
    "\n",
    "Generate actionable insights and weather-based optimization recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nWeather Correlation Analysis - Key Insights and Recommendations:\")\nprint(\"=\" * 80)\n\n# Generate insights based on weather correlation analysis\ninsights = []\nrecommendations = []\n\n# PV-weather insights\nif pv_weather_analysis and 'correlations' in pv_weather_analysis:\n    strongest_pv_corr = max(pv_weather_analysis['correlations'].items(), key=lambda x: abs(x[1]))\n    insights.append(f\"Strongest PV correlation: {strongest_pv_corr[0]} ({strongest_pv_corr[1]:+.3f})\")\n    \n    if 'temperature_analysis' in pv_weather_analysis:\n        temp_analysis = pv_weather_analysis['temperature_analysis']\n        if temp_analysis.get('optimal_temp'):\n            insights.append(f\"Optimal PV temperature: {temp_analysis['optimal_temp']:.1f}°C\")\n            recommendations.append(\"Monitor PV efficiency during hot weather (>30°C)\")\n    \n    if abs(strongest_pv_corr[1]) > 0.7:\n        recommendations.append(f\"Use {strongest_pv_corr[0]} for accurate PV forecasting\")\n\n# Heating-weather insights\nif heating_weather_analysis and 'correlations' in heating_weather_analysis:\n    strongest_heat_corr = max(heating_weather_analysis['correlations'].items(), key=lambda x: abs(x[1]))\n    insights.append(f\"Strongest heating correlation: {strongest_heat_corr[0]} ({strongest_heat_corr[1]:+.3f})\")\n    \n    if 'temperature_analysis' in heating_weather_analysis:\n        temp_analysis = heating_weather_analysis['temperature_analysis']\n        if temp_analysis.get('heating_threshold'):\n            threshold = temp_analysis['heating_threshold']\n            insights.append(f\"Heating threshold temperature: {threshold:.1f}°C\")\n            recommendations.append(f\"Pre-heat buildings when temperature drops below {threshold:.0f}°C\")\n    \n    if 'hdd_analysis' in heating_weather_analysis:\n        hdd_coeff = heating_weather_analysis['hdd_analysis']['coefficient']\n        insights.append(f\"Heating demand: {hdd_coeff:.0f}W per degree-hour below 18°C\")\n        recommendations.append(\"Use heating degree hours for demand forecasting\")\n\n# Total consumption insights\nif consumption_weather_analysis and 'correlations' in consumption_weather_analysis:\n    strongest_cons_corr = max(consumption_weather_analysis['correlations'].items(), key=lambda x: abs(x[1]))\n    insights.append(f\"Strongest consumption correlation: {strongest_cons_corr[0]} ({strongest_cons_corr[1]:+.3f})\")\n    \n    if 'day_night_analysis' in consumption_weather_analysis:\n        day_night = consumption_weather_analysis['day_night_analysis']\n        ratio = day_night['day_night_ratio']\n        insights.append(f\"Day/night consumption ratio: {ratio:.2f}\")\n        \n        if ratio > 1.5:\n            recommendations.append(\"Significant day/night difference - optimize time-of-use schedules\")\n    \n    if 'extreme_weather' in consumption_weather_analysis:\n        extreme = consumption_weather_analysis['extreme_weather']\n        hot_impact = (extreme['hot_consumption'] - extreme['normal_consumption']) / extreme['normal_consumption'] * 100\n        cold_impact = (extreme['cold_consumption'] - extreme['normal_consumption']) / extreme['normal_consumption'] * 100\n        \n        if abs(hot_impact) > 10:\n            insights.append(f\"Hot weather impact: {hot_impact:+.1f}% consumption change\")\n        if abs(cold_impact) > 10:\n            insights.append(f\"Cold weather impact: {cold_impact:+.1f}% consumption change\")\n\n# Weather prediction model insights\nif weather_prediction_models:\n    for model_type, model_data in weather_prediction_models.items():\n        best_model = model_data['best_model']\n        best_r2 = model_data['results'][best_model]['r2']\n        \n        insights.append(f\"{model_type.replace('_', ' ').title()} prediction: {best_model} model (R²={best_r2:.3f})\")\n        \n        if best_r2 > 0.7:\n            recommendations.append(f\"Implement weather-based {model_type.replace('_', ' ')} forecasting\")\n        elif best_r2 < 0.5:\n            recommendations.append(f\"Improve {model_type.replace('_', ' ')} model with additional features\")\n\n# Extreme weather insights\nif extreme_weather_analysis and 'performance_impact' in extreme_weather_analysis:\n    high_impact_events = []\n    \n    for event, perf in extreme_weather_analysis['performance_impact'].items():\n        deviation = abs(perf['performance_ratio'] - 1.0)\n        if deviation > 0.2:  # >20% impact\n            high_impact_events.append((event, perf['performance_ratio']))\n    \n    if high_impact_events:\n        insights.append(f\"High-impact weather events: {len(high_impact_events)} identified\")\n        recommendations.append(\"Develop weather-adaptive control strategies for extreme conditions\")\n        \n        # Find most problematic event\n        worst_event = max(high_impact_events, key=lambda x: abs(x[1] - 1.0))\n        event_name = worst_event[0].replace('_', ' ').title()\n        impact_pct = (worst_event[1] - 1.0) * 100\n        recommendations.append(f\"Priority: Address {event_name} impact ({impact_pct:+.0f}% performance change)\")\n\n# Seasonal insights\nif heating_weather_analysis and 'monthly_pattern' in heating_weather_analysis:\n    monthly_data = pd.DataFrame(heating_weather_analysis['monthly_pattern'])\n    if not monthly_data.empty and 'mean' in monthly_data.columns:\n        winter_months = [12, 1, 2]\n        summer_months = [6, 7, 8]\n        \n        winter_avg = monthly_data.loc[monthly_data.index.isin(winter_months), 'mean'].mean()\n        summer_avg = monthly_data.loc[monthly_data.index.isin(summer_months), 'mean'].mean()\n        \n        if not np.isnan(winter_avg) and not np.isnan(summer_avg):\n            seasonal_ratio = winter_avg / summer_avg if summer_avg > 0 else float('inf')\n            insights.append(f\"Seasonal heating variation: {seasonal_ratio:.1f}x winter vs summer\")\n            \n            if seasonal_ratio > 5:\n                recommendations.append(\"High seasonal variation - implement season-specific control strategies\")\n\n# Display insights and recommendations\nprint(\"\\nKey Insights:\")\nfor i, insight in enumerate(insights, 1):\n    print(f\"{i}. {insight}\")\n\nprint(\"\\nWeather-Based Optimization Recommendations:\")\nfor i, rec in enumerate(recommendations, 1):\n    print(f\"{i}. {rec}\")\n\n# Summary statistics\nprint(\"\\nSummary Statistics:\")\nprint(\"-\" * 40)\nif not weather_hourly.empty:\n    print(f\"Weather data analyzed: {len(weather_hourly)} hours ({len(weather_hourly)/24:.1f} days)\")\n    print(f\"Weather parameters: {len(weather_hourly.columns)}\")\n\nif pv_weather_analysis:\n    print(f\"PV-weather correlations: {len(pv_weather_analysis.get('correlations', {}))}\")\n    print(f\"PV daylight hours analyzed: {pv_weather_analysis.get('daylight_hours_analyzed', 0)}\")\n\nif heating_weather_analysis:\n    print(f\"Heating-weather correlations: {len(heating_weather_analysis.get('correlations', {}))}\")\n    print(f\"Heating rooms analyzed: {len(heating_weather_analysis.get('rooms_analyzed', []))}\")\n\nif weather_prediction_models:\n    print(f\"Weather-based models developed: {len(weather_prediction_models)}\")\n    \n    for model_type, model_data in weather_prediction_models.items():\n        best_r2 = max([r['r2'] for r in model_data['results'].values()])\n        print(f\"  {model_type.replace('_', ' ').title()}: R² = {best_r2:.3f}\")\n\nif extreme_weather_analysis:\n    event_count = len(extreme_weather_analysis.get('events', {}))\n    impact_count = len(extreme_weather_analysis.get('performance_impact', {}))\n    print(f\"Extreme weather events analyzed: {event_count}\")\n    print(f\"Performance impacts identified: {impact_count}\")\n\nprint(f\"\\nWeather correlation analysis completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weather correlation analysis results\nimport pickle\nfrom pathlib import Path\n\n# Create comprehensive results dictionary\nweather_correlation_results = {\n    'analysis_period': {'start': start_date, 'end': end_date},\n    'weather_data_summary': {\n        'hours_analyzed': len(weather_hourly) if not weather_hourly.empty else 0,\n        'parameters_available': list(weather_hourly.columns) if not weather_hourly.empty else [],\n        'data_quality': 'Good' if not weather_hourly.empty else 'No data'\n    },\n    'pv_weather_analysis': pv_weather_analysis,\n    'heating_weather_analysis': heating_weather_analysis,\n    'consumption_weather_analysis': consumption_weather_analysis,\n    'weather_prediction_models': weather_prediction_models,\n    'extreme_weather_analysis': extreme_weather_analysis,\n    'insights': insights,\n    'recommendations': recommendations\n}\n\n# Save to files\nresults_dir = Path('../../../data/processed')\nresults_dir.mkdir(parents=True, exist_ok=True)\n\n# Save as pickle for programmatic use\nwith open(results_dir / 'weather_correlation_results.pkl', 'wb') as f:\n    pickle.dump(weather_correlation_results, f)\n\n# Save weather correlations as CSV\ncorrelations_data = []\n\nif pv_weather_analysis and 'correlations' in pv_weather_analysis:\n    for param, corr in pv_weather_analysis['correlations'].items():\n        correlations_data.append({'system': 'PV Production', 'weather_parameter': param, 'correlation': corr})\n\nif heating_weather_analysis and 'correlations' in heating_weather_analysis:\n    for param, corr in heating_weather_analysis['correlations'].items():\n        correlations_data.append({'system': 'Heating Demand', 'weather_parameter': param, 'correlation': corr})\n\nif consumption_weather_analysis and 'correlations' in consumption_weather_analysis:\n    for param, corr in consumption_weather_analysis['correlations'].items():\n        correlations_data.append({'system': 'Total Consumption', 'weather_parameter': param, 'correlation': corr})\n\nif correlations_data:\n    correlations_df = pd.DataFrame(correlations_data)\n    correlations_df.to_csv(results_dir / 'weather_correlations.csv', index=False)\n\n# Save prediction model results\nif weather_prediction_models:\n    model_results_data = []\n    for model_type, model_data in weather_prediction_models.items():\n        for model_name, results in model_data['results'].items():\n            model_results_data.append({\n                'prediction_target': model_type,\n                'model': model_name,\n                'mae': results['mae'],\n                'rmse': results['rmse'],\n                'r2': results['r2'],\n                'features_used': ', '.join(model_data['features']),\n                'training_samples': model_data['training_samples']\n            })\n    \n    if model_results_data:\n        model_results_df = pd.DataFrame(model_results_data)\n        model_results_df.to_csv(results_dir / 'weather_prediction_models.csv', index=False)\n\n# Save summary as text\nwith open(results_dir / 'weather_correlation_summary.txt', 'w') as f:\n    f.write(\"Weather Correlation Analysis Summary\\n\")\n    f.write(\"=\" * 40 + \"\\n\\n\")\n    f.write(f\"Analysis Period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\\n\")\n    f.write(f\"Weather Data Hours: {len(weather_hourly) if not weather_hourly.empty else 0}\\n\\n\")\n    \n    f.write(\"Key Insights:\\n\")\n    for i, insight in enumerate(insights, 1):\n        f.write(f\"{i}. {insight}\\n\")\n    \n    f.write(\"\\nRecommendations:\\n\")\n    for i, rec in enumerate(recommendations, 1):\n        f.write(f\"{i}. {rec}\\n\")\n    \n    if weather_prediction_models:\n        f.write(\"\\nWeather Prediction Model Performance:\\n\")\n        for model_type, model_data in weather_prediction_models.items():\n            best_model = model_data['best_model']\n            best_results = model_data['results'][best_model]\n            f.write(f\"  {model_type.replace('_', ' ').title()}: {best_model}\\n\")\n            f.write(f\"    R² = {best_results['r2']:.3f}, MAE = {best_results['mae']:.0f}\\n\")\n    \n    if extreme_weather_analysis and 'events' in extreme_weather_analysis:\n        f.write(\"\\nExtreme Weather Events:\\n\")\n        for event_type, data in extreme_weather_analysis['events'].items():\n            f.write(f\"  {event_type.replace('_', ' ').title()}: {data['hours']} hours\\n\")\n\nprint(\"\\nWeather correlation analysis results saved to:\")\nprint(f\"  - {results_dir / 'weather_correlation_results.pkl'}\")\nif correlations_data:\n    print(f\"  - {results_dir / 'weather_correlations.csv'}\")\nif weather_prediction_models:\n    print(f\"  - {results_dir / 'weather_prediction_models.csv'}\")\nprint(f\"  - {results_dir / 'weather_correlation_summary.txt'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}