{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Analysis with PV Export Constraints\n",
    "\n",
    "This notebook analyzes data quality considering your PV system's unique constraints:\n",
    "- Historical period with export disabled (forced self-consumption)\n",
    "- Current period with price-based conditional export\n",
    "- 16-room relay-controlled heating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Import PEMS v2 modules\n",
    "import sys\n",
    "sys.path.append('../../..')  # Adjust path as needed\n",
    "\n",
    "from pems_v2.analysis.data_extraction import DataExtractor\n",
    "from pems_v2.analysis.data_preprocessing import (\n",
    "    DataValidator, OutlierDetector, GapFiller,\n",
    "    RelayDataProcessor, PVDataProcessor\n",
    ")\n",
    "from pems_v2.analysis.visualization import AnalysisVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Extraction and Initial Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data extractor\n",
    "extractor = DataExtractor()\n",
    "\n",
    "# Define analysis period\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=730)  # 2 years of data\n",
    "\n",
    "print(f\"Analysis period: {start_date.date()} to {end_date.date()}\")\n",
    "\n",
    "# Extract all data types\n",
    "print(\"\\nExtracting data...\")\n",
    "all_data = extractor.extract_all_data(\n",
    "    start_time=start_date.isoformat(),\n",
    "    end_time=end_date.isoformat()\n",
    ")\n",
    "\n",
    "# Display data availability\n",
    "print(\"\\n=== Data Availability Summary ===\")\n",
    "for data_type, data in all_data.items():\n",
    "    if isinstance(data, dict):\n",
    "        if 'error' in data:\n",
    "            print(f\"{data_type}: ERROR - {data['error']}\")\n",
    "        else:\n",
    "            # For room data\n",
    "            room_count = len([k for k in data.keys() if k not in ['error', 'warning']])\n",
    "            print(f\"{data_type}: {room_count} rooms\")\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        print(f\"{data_type}: {len(data)} records, {len(data.columns)} columns\")\n",
    "        if not data.empty:\n",
    "            print(f\"  Date range: {data.index.min()} to {data.index.max()}\")\n",
    "    else:\n",
    "        print(f\"{data_type}: Unknown format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PV Data Quality Analysis with Export Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processors and validators\n",
    "pv_processor = PVDataProcessor()\n",
    "validator = DataValidator()\n",
    "visualizer = AnalysisVisualizer()\n",
    "\n",
    "# Process PV data\n",
    "pv_data = all_data.get('pv', pd.DataFrame())\n",
    "price_data = all_data.get('prices', pd.DataFrame())\n",
    "\n",
    "if not pv_data.empty:\n",
    "    print(\"=== PV Data Validation ===\")\n",
    "    pv_validation = validator.validate_pv_data(pv_data)\n",
    "    print(f\"Valid: {pv_validation['valid']}\")\n",
    "    \n",
    "    if pv_validation['warnings']:\n",
    "        print(\"\\nWarnings:\")\n",
    "        for warning in pv_validation['warnings']:\n",
    "            print(f\"  - {warning}\")\n",
    "    \n",
    "    # Process PV data with export constraint analysis\n",
    "    print(\"\\n=== PV Export Constraint Analysis ===\")\n",
    "    pv_analysis = pv_processor.process_pv_data(pv_data, price_data)\n",
    "    \n",
    "    # Display export period detection\n",
    "    if 'export_periods' in pv_analysis:\n",
    "        periods = pv_analysis['export_periods']\n",
    "        if 'policy_change_date' in periods:\n",
    "            print(f\"\\nExport Policy Change Detected: {periods['policy_change_date']}\")\n",
    "            print(f\"Pre-export period: {periods['pre_export_period']['start']} to {periods['pre_export_period']['end']}\")\n",
    "            print(f\"Post-export period: {periods['post_export_period']['start']} to {periods['post_export_period']['end']}\")\n",
    "    \n",
    "    # Display production analysis\n",
    "    if 'production_analysis' in pv_analysis:\n",
    "        prod = pv_analysis['production_analysis']\n",
    "        print(f\"\\n=== Production Statistics ===\")\n",
    "        print(f\"Total production: {prod.get('total_production_kwh', 0):.1f} kWh\")\n",
    "        print(f\"Daily average: {prod.get('daily_avg_kwh', 0):.1f} kWh\")\n",
    "        print(f\"Peak power: {prod.get('peak_power_kw', 0):.1f} kW\")\n",
    "        print(f\"Capacity factor: {prod.get('capacity_factor', 0):.1%}\")\n",
    "else:\n",
    "    print(\"No PV data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Self-Consumption and Curtailment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pv_data.empty and 'export_periods' in pv_analysis:\n",
    "    # Visualize export constraint impact\n",
    "    export_date = pv_analysis['export_periods'].get('policy_change_date')\n",
    "    \n",
    "    if export_date:\n",
    "        fig = visualizer.plot_pv_export_constraint_analysis(\n",
    "            pv_data, price_data, export_date,\n",
    "            save_path='pv_export_constraints.html'\n",
    "        )\n",
    "        fig.show()\n",
    "    \n",
    "    # Display curtailment analysis\n",
    "    if 'curtailment' in pv_analysis:\n",
    "        curt = pv_analysis['curtailment']\n",
    "        print(\"\\n=== Curtailment Analysis ===\")\n",
    "        print(f\"Total curtailment: {curt.get('total_curtailment_kwh', 0):.1f} kWh\")\n",
    "        print(f\"Average daily curtailment: {curt.get('avg_daily_curtailment_kwh', 0):.1f} kWh\")\n",
    "        print(f\"Curtailment ratio: {curt.get('curtailment_ratio', 0):.1%}\")\n",
    "        \n",
    "        # Monthly curtailment pattern\n",
    "        if 'curtailment_by_month' in curt:\n",
    "            monthly_curt = pd.Series(curt['curtailment_by_month'])\n",
    "            if not monthly_curt.empty:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                monthly_curt.plot(kind='bar')\n",
    "                plt.title('Monthly Curtailment (kWh)')\n",
    "                plt.xlabel('Month')\n",
    "                plt.ylabel('Curtailment (kWh)')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.tight_layout()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Relay System Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process relay data\n",
    "relay_processor = RelayDataProcessor()\n",
    "room_data = all_data.get('rooms', {})\n",
    "\n",
    "if room_data and not isinstance(room_data, pd.DataFrame):\n",
    "    print(\"=== Relay System Analysis ===\")\n",
    "    relay_analysis = relay_processor.process_relay_data(room_data)\n",
    "    \n",
    "    # Display system-wide statistics\n",
    "    if 'system_totals' in relay_analysis:\n",
    "        system = relay_analysis['system_totals']\n",
    "        print(f\"\\nSystem Statistics:\")\n",
    "        print(f\"Total rooms: {system.get('total_rooms', 0)}\")\n",
    "        print(f\"Total capacity: {system.get('total_installed_capacity_kw', 0):.1f} kW\")\n",
    "        print(f\"Peak demand: {system.get('peak_demand_kw', 0):.1f} kW\")\n",
    "        print(f\"Average demand: {system.get('average_demand_kw', 0):.1f} kW\")\n",
    "        print(f\"Load factor: {system.get('load_factor', 0):.1%}\")\n",
    "        print(f\"Diversity factor: {system.get('diversity_factor', 0):.2f}\")\n",
    "    \n",
    "    # Room-by-room statistics\n",
    "    print(\"\\n=== Room-by-Room Analysis ===\")\n",
    "    room_stats = []\n",
    "    \n",
    "    for room_name, room_analysis in relay_analysis.items():\n",
    "        if room_name != 'system_totals' and isinstance(room_analysis, dict):\n",
    "            if 'switching_statistics' in room_analysis:\n",
    "                stats = room_analysis['switching_statistics']\n",
    "                room_stats.append({\n",
    "                    'Room': room_name,\n",
    "                    'Power (kW)': room_analysis.get('power_rating_kw', 0),\n",
    "                    'On Time %': stats.get('on_time_percentage', 0),\n",
    "                    'Switches/Day': stats.get('switches_per_day', 0),\n",
    "                    'Avg On Duration (min)': stats.get('avg_on_duration_minutes', 0)\n",
    "                })\n",
    "    \n",
    "    if room_stats:\n",
    "        room_df = pd.DataFrame(room_stats)\n",
    "        room_df = room_df.sort_values('On Time %', ascending=False)\n",
    "        print(room_df.to_string(index=False))\n",
    "        \n",
    "        # Visualize room usage patterns\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # On-time percentage\n",
    "        room_df.plot(x='Room', y='On Time %', kind='bar', ax=ax1)\n",
    "        ax1.set_title('Relay On-Time Percentage by Room')\n",
    "        ax1.set_ylabel('On Time (%)')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Switching frequency\n",
    "        room_df.plot(x='Room', y='Switches/Day', kind='bar', ax=ax2, color='orange')\n",
    "        ax2.set_title('Daily Switching Frequency by Room')\n",
    "        ax2.set_ylabel('Switches per Day')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Gap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data gaps across all sources\n",
    "print(\"=== Data Gap Analysis ===\")\n",
    "\n",
    "gap_summary = []\n",
    "\n",
    "# PV data gaps\n",
    "if not pv_data.empty:\n",
    "    pv_gaps = pv_data.index.to_series().diff()\n",
    "    large_gaps = pv_gaps[pv_gaps > pd.Timedelta(hours=2)]\n",
    "    gap_summary.append({\n",
    "        'Data Source': 'PV System',\n",
    "        'Total Gaps': len(large_gaps),\n",
    "        'Max Gap (hours)': large_gaps.max().total_seconds() / 3600 if len(large_gaps) > 0 else 0,\n",
    "        'Total Gap Time (hours)': large_gaps.sum().total_seconds() / 3600 if len(large_gaps) > 0 else 0\n",
    "    })\n",
    "\n",
    "# Weather data gaps\n",
    "weather_data = all_data.get('weather', pd.DataFrame())\n",
    "if not weather_data.empty:\n",
    "    weather_gaps = weather_data.index.to_series().diff()\n",
    "    large_gaps = weather_gaps[weather_gaps > pd.Timedelta(hours=2)]\n",
    "    gap_summary.append({\n",
    "        'Data Source': 'Weather',\n",
    "        'Total Gaps': len(large_gaps),\n",
    "        'Max Gap (hours)': large_gaps.max().total_seconds() / 3600 if len(large_gaps) > 0 else 0,\n",
    "        'Total Gap Time (hours)': large_gaps.sum().total_seconds() / 3600 if len(large_gaps) > 0 else 0\n",
    "    })\n",
    "\n",
    "# Room data gaps\n",
    "if relay_analysis and 'system_totals' not in room_data:\n",
    "    for room_name, room_analysis in relay_analysis.items():\n",
    "        if room_name != 'system_totals' and 'gap_analysis' in room_analysis:\n",
    "            gap_info = room_analysis['gap_analysis']\n",
    "            gap_summary.append({\n",
    "                'Data Source': f'Room: {room_name}',\n",
    "                'Total Gaps': gap_info.get('total_gaps', 0),\n",
    "                'Max Gap (hours)': gap_info.get('largest_gap_hours', 0),\n",
    "                'Total Gap Time (hours)': gap_info.get('total_gap_duration_hours', 0)\n",
    "            })\n",
    "\n",
    "if gap_summary:\n",
    "    gap_df = pd.DataFrame(gap_summary)\n",
    "    gap_df = gap_df.sort_values('Total Gap Time (hours)', ascending=False)\n",
    "    print(gap_df.to_string(index=False))\n",
    "    \n",
    "    # Visualize gaps\n",
    "    if len(gap_df) > 5:\n",
    "        # Show only top sources with gaps\n",
    "        gap_df_top = gap_df.head(10)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        gap_df_top.plot(x='Data Source', y='Total Gap Time (hours)', kind='bar')\n",
    "        plt.title('Data Gaps by Source (Top 10)')\n",
    "        plt.xlabel('Data Source')\n",
    "        plt.ylabel('Total Gap Time (hours)')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in key measurements\n",
    "outlier_detector = OutlierDetector()\n",
    "\n",
    "print(\"=== Outlier Detection ===\")\n",
    "\n",
    "# PV production outliers\n",
    "if not pv_data.empty and 'InputPower' in pv_data.columns:\n",
    "    pv_outliers = outlier_detector.detect_statistical_outliers(\n",
    "        pv_data['InputPower'], method='modified_zscore'\n",
    "    )\n",
    "    pv_outlier_count = pv_outliers.sum()\n",
    "    print(f\"\\nPV Production outliers: {pv_outlier_count} ({pv_outlier_count/len(pv_data)*100:.2f}%)\")\n",
    "    \n",
    "    if pv_outlier_count > 0:\n",
    "        # Show outlier distribution by hour\n",
    "        outlier_hours = pv_data[pv_outliers].index.hour.value_counts().sort_index()\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        outlier_hours.plot(kind='bar')\n",
    "        plt.title('PV Production Outliers by Hour of Day')\n",
    "        plt.xlabel('Hour')\n",
    "        plt.ylabel('Number of Outliers')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Temperature outliers for each room\n",
    "temp_outlier_summary = []\n",
    "for room_name, room_df in room_data.items():\n",
    "    if isinstance(room_df, pd.DataFrame) and not room_df.empty:\n",
    "        temp_col = None\n",
    "        for col in room_df.columns:\n",
    "            if 'temp' in col.lower():\n",
    "                temp_col = col\n",
    "                break\n",
    "        \n",
    "        if temp_col:\n",
    "            outliers = outlier_detector.detect_contextual_outliers(\n",
    "                room_df[temp_col], context_window='24H'\n",
    "            )\n",
    "            outlier_count = outliers.sum()\n",
    "            temp_outlier_summary.append({\n",
    "                'Room': room_name,\n",
    "                'Outliers': outlier_count,\n",
    "                'Percentage': f\"{outlier_count/len(room_df)*100:.2f}%\"\n",
    "            })\n",
    "\n",
    "if temp_outlier_summary:\n",
    "    print(\"\\nTemperature outliers by room:\")\n",
    "    outlier_df = pd.DataFrame(temp_outlier_summary)\n",
    "    outlier_df = outlier_df.sort_values('Outliers', ascending=False)\n",
    "    print(outlier_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Data Quality Recommendations ===\")\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# PV system recommendations\n",
    "if 'curtailment' in pv_analysis:\n",
    "    curt_ratio = pv_analysis['curtailment'].get('curtailment_ratio', 0)\n",
    "    if curt_ratio > 0.1:  # More than 10% curtailment\n",
    "        recommendations.append({\n",
    "            'Priority': 'HIGH',\n",
    "            'Area': 'PV System',\n",
    "            'Issue': f'High curtailment ratio ({curt_ratio:.1%})',\n",
    "            'Recommendation': 'Consider battery storage or load shifting to capture curtailed energy'\n",
    "        })\n",
    "\n",
    "# Export behavior recommendations\n",
    "if 'export_behavior' in pv_analysis:\n",
    "    export_freq = pv_analysis['export_behavior'].get('export_frequency', 0)\n",
    "    if export_freq < 0.5:  # Exporting less than 50% of days\n",
    "        recommendations.append({\n",
    "            'Priority': 'MEDIUM',\n",
    "            'Area': 'PV Export',\n",
    "            'Issue': f'Low export frequency ({export_freq:.1%})',\n",
    "            'Recommendation': 'Review price threshold settings for export optimization'\n",
    "        })\n",
    "\n",
    "# Relay system recommendations\n",
    "if 'system_totals' in relay_analysis:\n",
    "    diversity_factor = relay_analysis['system_totals'].get('diversity_factor', 1)\n",
    "    if diversity_factor > 0.8:  # High simultaneous usage\n",
    "        recommendations.append({\n",
    "            'Priority': 'HIGH',\n",
    "            'Area': 'Relay System',\n",
    "            'Issue': f'High diversity factor ({diversity_factor:.2f})',\n",
    "            'Recommendation': 'Implement relay coordination to reduce peak demand'\n",
    "        })\n",
    "\n",
    "# Data quality recommendations\n",
    "if gap_summary:\n",
    "    total_gap_hours = sum(item['Total Gap Time (hours)'] for item in gap_summary)\n",
    "    if total_gap_hours > 100:  # More than 100 hours of gaps\n",
    "        recommendations.append({\n",
    "            'Priority': 'MEDIUM',\n",
    "            'Area': 'Data Quality',\n",
    "            'Issue': f'Significant data gaps ({total_gap_hours:.0f} hours total)',\n",
    "            'Recommendation': 'Investigate data collection reliability and implement gap filling'\n",
    "        })\n",
    "\n",
    "if recommendations:\n",
    "    rec_df = pd.DataFrame(recommendations)\n",
    "    rec_df = rec_df.sort_values('Priority')\n",
    "    print(rec_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No critical data quality issues identified.\")\n",
    "\n",
    "# Save summary report\n",
    "print(\"\\n=== Analysis Summary ===\")\n",
    "print(f\"Analysis completed for period: {start_date.date()} to {end_date.date()}\")\n",
    "print(f\"Data sources analyzed: {len([k for k,v in all_data.items() if not (isinstance(v, dict) and 'error' in v)])}\")\n",
    "print(f\"Total recommendations: {len(recommendations)}\")\n",
    "print(f\"High priority issues: {len([r for r in recommendations if r.get('Priority') == 'HIGH'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}