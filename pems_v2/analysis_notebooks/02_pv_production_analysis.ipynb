{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PV Production Analysis\n",
    "\n",
    "This notebook analyzes photovoltaic (PV) production patterns, seasonal variations, and correlations with weather data.\n",
    "\n",
    "## Key Analysis Areas:\n",
    "1. **Production Patterns**: Daily, weekly, and seasonal patterns\n",
    "2. **Weather Correlations**: Impact of temperature, cloud cover, and solar radiation\n",
    "3. **Export Policy Impact**: Before/after export policy change analysis\n",
    "4. **Performance Metrics**: Capacity factor, efficiency analysis\n",
    "5. **Anomaly Detection**: Identify system issues or unusual performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path().absolute().parent.parent))\n",
    "\n",
    "from analysis.data_extraction import DataExtractor\n",
    "from analysis.pattern_analysis import PVAnalyzer\n",
    "from config.settings import PEMSSettings\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize settings and data extractor\n",
    "settings = PEMSSettings()\n",
    "extractor = DataExtractor(settings)\n",
    "pv_analyzer = PVAnalyzer()\n",
    "\n",
    "# Define analysis period\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=730)  # 2 years\n",
    "\n",
    "print(f\"Analysis period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PV and weather data\n",
    "try:\n",
    "    pv_data = await extractor.extract_pv_data(start_date, end_date)\n",
    "    weather_data = await extractor.extract_weather_data(start_date, end_date)\n",
    "    price_data = await extractor.extract_energy_prices(start_date, end_date)\n",
    "    \n",
    "    print(f\"PV data shape: {pv_data.shape}\")\n",
    "    print(f\"Weather data shape: {weather_data.shape}\")\n",
    "    print(f\"Price data shape: {price_data.shape if price_data is not None else 'None'}\")\n",
    "    \n",
    "    # Display data summary\n",
    "    print(\"\\nPV Data Columns:\")\n",
    "    print(pv_data.columns.tolist())\n",
    "    \n",
    "    print(\"\\nPV Data Sample:\")\n",
    "    display(pv_data.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Load from saved files if extraction fails\n",
    "    try:\n",
    "        pv_data = extractor.load_from_parquet(\"pv_data\")\n",
    "        weather_data = extractor.load_from_parquet(\"weather_data\")\n",
    "        print(\"Loaded data from saved parquet files\")\n",
    "    except:\n",
    "        print(\"Failed to load saved data. Please run data extraction first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Production Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pv_data.empty:\n",
    "    # Run PV analysis\n",
    "    pv_results = pv_analyzer.analyze_pv_production(pv_data, weather_data)\n",
    "    \n",
    "    # Display basic statistics\n",
    "    if \"basic_stats\" in pv_results:\n",
    "        stats = pv_results[\"basic_stats\"]\n",
    "        \n",
    "        print(\"=== PV PRODUCTION STATISTICS ===\")\n",
    "        print(f\"Total Energy Generated: {stats.get('total_energy_kwh', 0):.1f} kWh\")\n",
    "        print(f\"Maximum Power: {stats.get('max_power', 0):.1f} W\")\n",
    "        print(f\"Mean Power: {stats.get('mean_power', 0):.1f} W\")\n",
    "        print(f\"Capacity Factor: {stats.get('capacity_factor', 0)*100:.1f}%\")\n",
    "        print(f\"Daylight Capacity Factor: {stats.get('daylight_capacity_factor', 0)*100:.1f}%\")\n",
    "        print(f\"Peak Production Months: {', '.join(map(str, stats.get('peak_months', [])))}\")\n",
    "        print(f\"Low Production Months: {', '.join(map(str, stats.get('low_months', [])))}\")\n",
    "else:\n",
    "    print(\"No PV data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Production Patterns Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pv_data.empty and 'InputPower' in pv_data.columns:\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Daily production pattern\n",
    "    hourly_avg = pv_data['InputPower'].groupby(pv_data.index.hour).mean()\n",
    "    axes[0, 0].plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2)\n",
    "    axes[0, 0].set_title('Average Daily Production Pattern')\n",
    "    axes[0, 0].set_xlabel('Hour of Day')\n",
    "    axes[0, 0].set_ylabel('Average Power (W)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Monthly production variation\n",
    "    monthly_total = pv_data['InputPower'].resample('M').sum() * 0.25 / 1000  # Convert to kWh\n",
    "    axes[0, 1].bar(range(1, 13), \n",
    "                   [monthly_total[monthly_total.index.month == m].mean() for m in range(1, 13)])\n",
    "    axes[0, 1].set_title('Average Monthly Production')\n",
    "    axes[0, 1].set_xlabel('Month')\n",
    "    axes[0, 1].set_ylabel('Average Monthly Energy (kWh)')\n",
    "    axes[0, 1].set_xticks(range(1, 13))\n",
    "    \n",
    "    # 3. Weekly pattern\n",
    "    weekly_avg = pv_data['InputPower'].groupby(pv_data.index.weekday).mean()\n",
    "    weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    axes[1, 0].bar(weekdays, weekly_avg.values)\n",
    "    axes[1, 0].set_title('Average Production by Day of Week')\n",
    "    axes[1, 0].set_ylabel('Average Power (W)')\n",
    "    \n",
    "    # 4. Production time series (last 3 months)\n",
    "    recent_data = pv_data.last('3M')['InputPower']\n",
    "    daily_production = recent_data.resample('D').sum() * 0.25 / 1000\n",
    "    axes[1, 1].plot(daily_production.index, daily_production.values, alpha=0.7)\n",
    "    axes[1, 1].set_title('Daily Production (Last 3 Months)')\n",
    "    axes[1, 1].set_xlabel('Date')\n",
    "    axes[1, 1].set_ylabel('Daily Energy (kWh)')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Weather Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"weather_correlations\" in pv_results:\n",
    "    correlations = pv_results[\"weather_correlations\"]\n",
    "    \n",
    "    print(\"=== WEATHER CORRELATIONS ===\")\n",
    "    if \"correlations\" in correlations:\n",
    "        # Create correlation plot\n",
    "        corr_data = correlations[\"correlations\"]\n",
    "        if corr_data:\n",
    "            variables = list(corr_data.keys())\n",
    "            corr_values = [corr_data[var][\"correlation\"] for var in variables]\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            colors = ['red' if x < 0 else 'green' for x in corr_values]\n",
    "            bars = plt.bar(variables, corr_values, color=colors, alpha=0.7)\n",
    "            plt.title('PV Production Correlation with Weather Variables')\n",
    "            plt.ylabel('Correlation Coefficient')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, value in zip(bars, corr_values):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01 * np.sign(value),\n",
    "                        f'{value:.3f}', ha='center', va='bottom' if value > 0 else 'top')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Print strongest correlations\n",
    "    if \"strongest_positive\" in correlations and correlations[\"strongest_positive\"]:\n",
    "        strongest = correlations[\"strongest_positive\"]\n",
    "        print(f\"Strongest positive correlation: {strongest[0]} ({strongest[1]['correlation']:.3f})\")\n",
    "    \n",
    "    if \"strongest_negative\" in correlations and correlations[\"strongest_negative\"]:\n",
    "        strongest = correlations[\"strongest_negative\"]\n",
    "        print(f\"Strongest negative correlation: {strongest[0]} ({strongest[1]['correlation']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Policy Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if export policy analysis is available\n",
    "if \"export_policy\" in pv_results:\n",
    "    export_policy = pv_results[\"export_policy\"]\n",
    "    \n",
    "    print(\"=== EXPORT POLICY IMPACT ===\")\n",
    "    if \"policy_change_date\" in export_policy:\n",
    "        change_date = export_policy[\"policy_change_date\"]\n",
    "        print(f\"Export policy change detected: {change_date}\")\n",
    "        print(f\"Export consistency after change: {export_policy.get('export_consistency', 0):.1%}\")\n",
    "        print(f\"Days analyzed post-change: {export_policy.get('days_analyzed', 0)}\")\n",
    "        \n",
    "        # Pre/post export analysis\n",
    "        if \"pre_export_analysis\" in pv_results:\n",
    "            pre_analysis = pv_results[\"pre_export_analysis\"]\n",
    "            print(f\"\\nPre-export period (self-consumption):\")\n",
    "            print(f\"  Duration: {pre_analysis.get('period_duration_days', 0)} days\")\n",
    "            print(f\"  Total production: {pre_analysis.get('total_production_kwh', 0):.1f} kWh\")\n",
    "            print(f\"  Self-consumption ratio: {pre_analysis.get('self_consumption_ratio', 0):.1%}\")\n",
    "            print(f\"  Estimated curtailment: {pre_analysis.get('estimated_curtailment_kwh', 0):.1f} kWh\")\n",
    "        \n",
    "        if \"post_export_analysis\" in pv_results:\n",
    "            post_analysis = pv_results[\"post_export_analysis\"]\n",
    "            print(f\"\\nPost-export period (price-based):\")\n",
    "            print(f\"  Total export: {post_analysis.get('total_export_kwh', 0):.1f} kWh\")\n",
    "            print(f\"  Estimated revenue: {post_analysis.get('estimated_total_revenue_czk', 0):.0f} CZK\")\n",
    "            print(f\"  Revenue per kWh: {post_analysis.get('revenue_per_kwh_czk', 0):.2f} CZK/kWh\")\n",
    "        \n",
    "        if \"optimization_potential\" in pv_results:\n",
    "            opt_potential = pv_results[\"optimization_potential\"]\n",
    "            print(f\"\\nOptimization potential:\")\n",
    "            print(f\"  Lost revenue from curtailment: {opt_potential.get('lost_revenue_curtailment_czk', 0):.0f} CZK\")\n",
    "            print(f\"  Storage value potential: {opt_potential.get('storage_value_potential_czk', 0):.0f} CZK\")\n",
    "    else:\n",
    "        print(\"No clear export policy change detected in the data\")\n",
    "else:\n",
    "    print(\"Export policy analysis not available (requires price data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Seasonal Analysis and Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"seasonal_patterns\" in pv_results:\n",
    "    seasonal = pv_results[\"seasonal_patterns\"]\n",
    "    \n",
    "    print(\"=== SEASONAL PATTERNS ===\")\n",
    "    if \"peak_season\" in seasonal:\n",
    "        print(f\"Peak production season: {seasonal['peak_season']}\")\n",
    "    \n",
    "    # Plot seasonal profiles if available\n",
    "    if \"seasonal_profiles\" in seasonal:\n",
    "        profiles = seasonal[\"seasonal_profiles\"]\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for season, profile in profiles.items():\n",
    "            if isinstance(profile, pd.Series):\n",
    "                plt.plot(profile.index, profile.values, label=season, marker='o', alpha=0.7)\n",
    "        \n",
    "        plt.title('Seasonal Production Profiles')\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Average Power (W)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    \n",
    "    # STL decomposition results\n",
    "    if \"decomposition\" in seasonal:\n",
    "        decomp = seasonal[\"decomposition\"]\n",
    "        print(f\"Seasonal strength: {decomp.get('seasonal_strength', 0):.3f}\")\n",
    "        print(f\"Trend strength: {decomp.get('trend_strength', 0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance and Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiency analysis\n",
    "if \"efficiency_analysis\" in pv_results:\n",
    "    efficiency = pv_results[\"efficiency_analysis\"]\n",
    "    \n",
    "    print(\"=== EFFICIENCY ANALYSIS ===\")\n",
    "    if \"temperature_efficiency\" in efficiency:\n",
    "        temp_eff = efficiency[\"temperature_efficiency\"]\n",
    "        print(\"Power output by temperature range:\")\n",
    "        for temp_range, stats in temp_eff.items():\n",
    "            print(f\"  {temp_range}: {stats['mean_power']:.0f}W (max: {stats['max_power']:.0f}W, samples: {stats['records']})\")\n",
    "    \n",
    "    if \"optimal_temperature_range\" in efficiency:\n",
    "        print(f\"Optimal temperature range: {efficiency['optimal_temperature_range']}\")\n",
    "\n",
    "# Clear sky analysis\n",
    "if \"clear_sky_analysis\" in pv_results:\n",
    "    clear_sky = pv_results[\"clear_sky_analysis\"]\n",
    "    \n",
    "    print(\"\\n=== CLEAR SKY PERFORMANCE ===\")\n",
    "    print(f\"Clear sky conditions: {clear_sky.get('clear_sky_percentage', 0):.1f}% of time\")\n",
    "    print(f\"Clear sky mean power: {clear_sky.get('clear_sky_mean_power', 0):.0f}W\")\n",
    "    print(f\"Cloudy sky mean power: {clear_sky.get('cloudy_sky_mean_power', 0):.0f}W\")\n",
    "    print(f\"Clear sky advantage: {clear_sky.get('clear_sky_advantage', 1):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"anomalies\" in pv_results:\n",
    "    anomalies = pv_results[\"anomalies\"]\n",
    "    \n",
    "    print(\"=== ANOMALY DETECTION ===\")\n",
    "    print(f\"Total anomalies detected: {anomalies.get('total_anomalies', 0)}\")\n",
    "    print(f\"Anomaly rate: {anomalies.get('anomaly_percentage', 0):.2f}%\")\n",
    "    print(f\"Zero production events: {anomalies.get('zero_production_events', 0)}\")\n",
    "    \n",
    "    if \"largest_anomaly\" in anomalies and anomalies[\"largest_anomaly\"][\"timestamp\"]:\n",
    "        largest = anomalies[\"largest_anomaly\"]\n",
    "        print(f\"Largest anomaly: {largest['value']:.0f}W at {largest['timestamp']}\")\n",
    "    \n",
    "    # Plot anomaly dates if available\n",
    "    if \"anomaly_dates\" in anomalies and anomalies[\"anomaly_dates\"]:\n",
    "        anomaly_dates = anomalies[\"anomaly_dates\"][:10]  # First 10\n",
    "        print(f\"\\nFirst 10 anomaly dates: {', '.join(map(str, anomaly_dates))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance for ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"feature_importance\" in pv_results:\n",
    "    feature_imp = pv_results[\"feature_importance\"]\n",
    "    \n",
    "    print(\"=== FEATURE IMPORTANCE FOR PV PREDICTION ===\")\n",
    "    if \"top_5_features\" in feature_imp:\n",
    "        top_features = feature_imp[\"top_5_features\"]\n",
    "        print(f\"Top 5 features: {', '.join(top_features)}\")\n",
    "        print(f\"Model R² score: {feature_imp.get('model_score', 0):.3f}\")\n",
    "        \n",
    "        # Plot feature importance\n",
    "        if \"feature_importance\" in feature_imp:\n",
    "            importance_dict = feature_imp[\"feature_importance\"]\n",
    "            if importance_dict:\n",
    "                features = list(importance_dict.keys())[:10]  # Top 10\n",
    "                importance = [importance_dict[f] for f in features]\n",
    "                \n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.barh(features, importance, alpha=0.7)\n",
    "                plt.title('Feature Importance for PV Production Prediction')\n",
    "                plt.xlabel('Importance Score')\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.tight_layout()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Performance for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"prediction_performance\" in pv_results:\n",
    "    pred_perf = pv_results[\"prediction_performance\"]\n",
    "    \n",
    "    print(\"=== PREDICTION MODEL PERFORMANCE ===\")\n",
    "    \n",
    "    # Display model comparison\n",
    "    models_data = []\n",
    "    for model_name, metrics in pred_perf.items():\n",
    "        if isinstance(metrics, dict) and \"mean_rmse\" in metrics:\n",
    "            models_data.append({\n",
    "                \"Model\": model_name,\n",
    "                \"RMSE\": f\"{metrics['mean_rmse']:.1f} ± {metrics.get('std_rmse', 0):.1f}\",\n",
    "                \"MAE\": f\"{metrics['mean_mae']:.1f} ± {metrics.get('std_mae', 0):.1f}\",\n",
    "                \"R²\": f\"{metrics['mean_r2']:.3f} ± {metrics.get('std_r2', 0):.3f}\"\n",
    "            })\n",
    "    \n",
    "    if models_data:\n",
    "        models_df = pd.DataFrame(models_data)\n",
    "        display(models_df)\n",
    "        \n",
    "        if \"best_model\" in pred_perf:\n",
    "            print(f\"\\nBest performing model: {pred_perf['best_model']}\")\n",
    "    else:\n",
    "        print(\"No valid model performance data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n",
    "\n",
    "Based on the analysis above, here are the key findings and recommendations for the PV system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PV SYSTEM ANALYSIS SUMMARY ===\")\n",
    "print()\n",
    "\n",
    "# Generate recommendations based on analysis results\n",
    "recommendations = []\n",
    "\n",
    "if \"basic_stats\" in pv_results:\n",
    "    stats = pv_results[\"basic_stats\"]\n",
    "    capacity_factor = stats.get('capacity_factor', 0)\n",
    "    \n",
    "    if capacity_factor < 0.15:\n",
    "        recommendations.append(\"LOW CAPACITY FACTOR: Consider system inspection for shading, soiling, or equipment issues\")\n",
    "    elif capacity_factor > 0.25:\n",
    "        recommendations.append(\"EXCELLENT PERFORMANCE: System is performing above average\")\n",
    "\n",
    "if \"anomalies\" in pv_results:\n",
    "    anomaly_rate = pv_results[\"anomalies\"].get('anomaly_percentage', 0)\n",
    "    if anomaly_rate > 5:\n",
    "        recommendations.append(f\"HIGH ANOMALY RATE ({anomaly_rate:.1f}%): Investigate system reliability\")\n",
    "\n",
    "if \"export_policy\" in pv_results and \"optimization_potential\" in pv_results:\n",
    "    lost_revenue = pv_results[\"optimization_potential\"].get('lost_revenue_curtailment_czk', 0)\n",
    "    if lost_revenue > 1000:\n",
    "        recommendations.append(f\"CURTAILMENT LOSSES: {lost_revenue:.0f} CZK lost - consider battery storage\")\n",
    "\n",
    "if \"weather_correlations\" in pv_results:\n",
    "    correlations = pv_results[\"weather_correlations\"]\n",
    "    if \"strongest_negative\" in correlations and correlations[\"strongest_negative\"]:\n",
    "        strongest_neg = correlations[\"strongest_negative\"]\n",
    "        if abs(strongest_neg[1][\"correlation\"]) > 0.5:\n",
    "            recommendations.append(f\"STRONG NEGATIVE CORRELATION with {strongest_neg[0]} - optimize for these conditions\")\n",
    "\n",
    "if recommendations:\n",
    "    print(\"KEY RECOMMENDATIONS:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "else:\n",
    "    print(\"SYSTEM STATUS: No major issues detected - system performing within normal parameters\")\n",
    "\n",
    "print(\"\\nAnalysis completed successfully!\")\n",
    "print(f\"Report generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}