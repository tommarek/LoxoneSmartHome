{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relay Optimization Strategies\n",
    "\n",
    "This notebook analyzes relay-controlled heating system optimization opportunities:\n",
    "- Peak demand reduction through relay coordination\n",
    "- Load shifting to match PV production\n",
    "- Predictive control based on weather forecasts\n",
    "- Integration with price-based optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Import PEMS v2 modules\n",
    "import sys\n",
    "sys.path.append('../../..')  # Adjust path as needed\n",
    "\n",
    "from pems_v2.analysis.data_extraction import DataExtractor\n",
    "from pems_v2.analysis.data_preprocessing import RelayDataProcessor\n",
    "from pems_v2.analysis.thermal_analysis import ThermalAnalyzer\n",
    "from pems_v2.analysis.visualization import AnalysisVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Current Relay System Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "extractor = DataExtractor()\n",
    "relay_processor = RelayDataProcessor()\n",
    "thermal_analyzer = ThermalAnalyzer()\n",
    "visualizer = AnalysisVisualizer()\n",
    "\n",
    "# Extract recent data for analysis\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=90)  # 3 months for detailed analysis\n",
    "\n",
    "print(f\"Analysis period: {start_date.date()} to {end_date.date()}\")\n",
    "\n",
    "# Extract all data\n",
    "all_data = extractor.extract_all_data(\n",
    "    start_time=start_date.isoformat(),\n",
    "    end_time=end_date.isoformat()\n",
    ")\n",
    "\n",
    "# Process relay data\n",
    "room_data = all_data.get('rooms', {})\n",
    "relay_analysis = relay_processor.process_relay_data(room_data)\n",
    "\n",
    "# Display current system performance\n",
    "if 'system_totals' in relay_analysis:\n",
    "    system = relay_analysis['system_totals']\n",
    "    print(\"\\n=== Current System Performance ===\")\n",
    "    print(f\"Peak demand: {system.get('peak_demand_kw', 0):.1f} kW\")\n",
    "    print(f\"Average demand: {system.get('average_demand_kw', 0):.1f} kW\")\n",
    "    print(f\"Total capacity: {system.get('total_installed_capacity_kw', 0):.1f} kW\")\n",
    "    print(f\"Load factor: {system.get('load_factor', 0):.1%}\")\n",
    "    print(f\"Diversity factor: {system.get('diversity_factor', 0):.2f}\")\n",
    "    print(f\"Peak hour: {system.get('peak_hour', 'N/A')}:00\")\n",
    "    \n",
    "    # Calculate potential savings\n",
    "    current_peak = system.get('peak_demand_kw', 0)\n",
    "    potential_peak = current_peak * 0.8  # 20% reduction target\n",
    "    print(f\"\\nOptimization potential:\")\n",
    "    print(f\"Target peak demand: {potential_peak:.1f} kW\")\n",
    "    print(f\"Potential reduction: {current_peak - potential_peak:.1f} kW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Peak Demand Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze peak demand patterns\n",
    "total_power_data = []\n",
    "\n",
    "# Reconstruct total power consumption timeline\n",
    "for room_name, room_analysis in relay_analysis.items():\n",
    "    if room_name != 'system_totals' and 'power_consumption' in room_analysis:\n",
    "        power_series = room_analysis['power_consumption']\n",
    "        if total_power_data is None:\n",
    "            total_power_data = power_series.to_frame(name=room_name)\n",
    "        else:\n",
    "            total_power_data = total_power_data.join(power_series.to_frame(name=room_name), how='outer')\n",
    "\n",
    "if len(total_power_data) > 0:\n",
    "    # Calculate total system power\n",
    "    total_power_data['total_power_kw'] = total_power_data.sum(axis=1) / 1000\n",
    "    \n",
    "    # Analyze peak events\n",
    "    peak_threshold = total_power_data['total_power_kw'].quantile(0.95)  # Top 5% of demand\n",
    "    peak_events = total_power_data[total_power_data['total_power_kw'] >= peak_threshold]\n",
    "    \n",
    "    print(f\"\\n=== Peak Demand Events ===\")\n",
    "    print(f\"Peak threshold: {peak_threshold:.1f} kW\")\n",
    "    print(f\"Number of peak events: {len(peak_events)}\")\n",
    "    \n",
    "    # Identify rooms contributing to peaks\n",
    "    room_contributions = {}\n",
    "    for room in total_power_data.columns[:-1]:  # Exclude total_power_kw\n",
    "        room_contributions[room] = (peak_events[room] > 0).sum() / len(peak_events) * 100\n",
    "    \n",
    "    # Sort by contribution\n",
    "    sorted_contributions = sorted(room_contributions.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nRooms active during peak events:\")\n",
    "    for room, pct in sorted_contributions[:10]:  # Top 10 contributors\n",
    "        print(f\"  {room}: {pct:.1f}%\")\n",
    "    \n",
    "    # Visualize peak patterns\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Daily peak pattern\n",
    "    daily_peaks = total_power_data.resample('D')['total_power_kw'].max()\n",
    "    axes[0, 0].plot(daily_peaks.index, daily_peaks.values)\n",
    "    axes[0, 0].axhline(y=peak_threshold, color='r', linestyle='--', label='95th percentile')\n",
    "    axes[0, 0].set_title('Daily Peak Demand')\n",
    "    axes[0, 0].set_ylabel('Peak Power (kW)')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Hourly pattern\n",
    "    hourly_avg = total_power_data.groupby(total_power_data.index.hour)['total_power_kw'].mean()\n",
    "    hourly_max = total_power_data.groupby(total_power_data.index.hour)['total_power_kw'].max()\n",
    "    axes[0, 1].plot(hourly_avg.index, hourly_avg.values, label='Average', linewidth=2)\n",
    "    axes[0, 1].plot(hourly_max.index, hourly_max.values, label='Maximum', linewidth=2)\n",
    "    axes[0, 1].set_title('Hourly Demand Pattern')\n",
    "    axes[0, 1].set_xlabel('Hour of Day')\n",
    "    axes[0, 1].set_ylabel('Power (kW)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Weekly pattern\n",
    "    weekday_avg = total_power_data.groupby(total_power_data.index.weekday)['total_power_kw'].mean()\n",
    "    axes[1, 0].bar(range(7), weekday_avg.values)\n",
    "    axes[1, 0].set_title('Average Demand by Weekday')\n",
    "    axes[1, 0].set_xlabel('Day of Week')\n",
    "    axes[1, 0].set_ylabel('Average Power (kW)')\n",
    "    axes[1, 0].set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "    \n",
    "    # Room contribution to peaks\n",
    "    top_contributors = dict(sorted_contributions[:8])\n",
    "    axes[1, 1].bar(range(len(top_contributors)), list(top_contributors.values()))\n",
    "    axes[1, 1].set_title('Room Contribution to Peak Events')\n",
    "    axes[1, 1].set_xlabel('Room')\n",
    "    axes[1, 1].set_ylabel('Active During Peaks (%)')\n",
    "    axes[1, 1].set_xticklabels(list(top_contributors.keys()), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Relay Coordination Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze simultaneous relay operation\n",
    "if len(total_power_data) > 0:\n",
    "    # Count simultaneous relays\n",
    "    relay_count = (total_power_data.iloc[:, :-1] > 0).sum(axis=1)\n",
    "    \n",
    "    # Analyze correlation between rooms\n",
    "    room_correlations = total_power_data.iloc[:, :-1].corr()\n",
    "    \n",
    "    print(\"=== Relay Coordination Analysis ===\")\n",
    "    print(f\"\\nSimultaneous relay statistics:\")\n",
    "    print(f\"Maximum simultaneous: {relay_count.max()} relays\")\n",
    "    print(f\"Average simultaneous: {relay_count.mean():.1f} relays\")\n",
    "    print(f\"95th percentile: {relay_count.quantile(0.95):.0f} relays\")\n",
    "    \n",
    "    # Find highly correlated room pairs (candidates for staggering)\n",
    "    high_correlations = []\n",
    "    for i in range(len(room_correlations.columns)):\n",
    "        for j in range(i+1, len(room_correlations.columns)):\n",
    "            corr_value = room_correlations.iloc[i, j]\n",
    "            if corr_value > 0.7:  # High correlation threshold\n",
    "                high_correlations.append({\n",
    "                    'Room 1': room_correlations.columns[i],\n",
    "                    'Room 2': room_correlations.columns[j],\n",
    "                    'Correlation': corr_value\n",
    "                })\n",
    "    \n",
    "    if high_correlations:\n",
    "        print(\"\\nHighly correlated room pairs (coordination candidates):\")\n",
    "        corr_df = pd.DataFrame(high_correlations)\n",
    "        corr_df = corr_df.sort_values('Correlation', ascending=False)\n",
    "        print(corr_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize correlation matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(room_correlations, dtype=bool))\n",
    "    sns.heatmap(room_correlations, mask=mask, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Room Relay Operation Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate potential peak reduction through coordination\n",
    "    # Simulate staggered operation for top correlated pairs\n",
    "    if high_correlations:\n",
    "        # Simple simulation: prevent simultaneous operation of highly correlated rooms\n",
    "        simulated_power = total_power_data.copy()\n",
    "        \n",
    "        for pair in high_correlations[:5]:  # Top 5 pairs\n",
    "            room1, room2 = pair['Room 1'], pair['Room 2']\n",
    "            # When both are on, delay one by 30 minutes\n",
    "            both_on = (simulated_power[room1] > 0) & (simulated_power[room2] > 0)\n",
    "            # Shift room2 operation when conflict exists\n",
    "            simulated_power.loc[both_on, room2] = 0\n",
    "        \n",
    "        # Recalculate total with coordination\n",
    "        simulated_power['coordinated_total_kw'] = simulated_power.iloc[:, :-2].sum(axis=1) / 1000\n",
    "        \n",
    "        original_peak = total_power_data['total_power_kw'].max()\n",
    "        coordinated_peak = simulated_power['coordinated_total_kw'].max()\n",
    "        \n",
    "        print(f\"\\n=== Coordination Impact ===\")\n",
    "        print(f\"Original peak: {original_peak:.1f} kW\")\n",
    "        print(f\"Coordinated peak: {coordinated_peak:.1f} kW\")\n",
    "        print(f\"Peak reduction: {original_peak - coordinated_peak:.1f} kW ({(original_peak - coordinated_peak)/original_peak*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PV Integration Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze potential for shifting load to PV production hours\n",
    "pv_data = all_data.get('pv', pd.DataFrame())\n",
    "weather_data = all_data.get('weather', pd.DataFrame())\n",
    "\n",
    "if not pv_data.empty and len(total_power_data) > 0:\n",
    "    print(\"=== PV Integration Analysis ===\")\n",
    "    \n",
    "    # Align PV and relay data\n",
    "    analysis_df = pd.DataFrame({\n",
    "        'relay_demand_kw': total_power_data['total_power_kw'],\n",
    "        'pv_production_kw': pv_data.get('InputPower', 0) / 1000\n",
    "    })\n",
    "    \n",
    "    # Calculate hourly patterns\n",
    "    hourly_patterns = analysis_df.groupby(analysis_df.index.hour).mean()\n",
    "    \n",
    "    # Find mismatch between production and consumption\n",
    "    hourly_patterns['mismatch_kw'] = hourly_patterns['relay_demand_kw'] - hourly_patterns['pv_production_kw']\n",
    "    \n",
    "    # Identify load shifting opportunities\n",
    "    pv_hours = hourly_patterns[hourly_patterns['pv_production_kw'] > 1.0].index  # Significant PV production\n",
    "    non_pv_hours = hourly_patterns[hourly_patterns['pv_production_kw'] <= 1.0].index\n",
    "    \n",
    "    current_pv_hour_load = hourly_patterns.loc[pv_hours, 'relay_demand_kw'].sum()\n",
    "    current_non_pv_hour_load = hourly_patterns.loc[non_pv_hours, 'relay_demand_kw'].sum()\n",
    "    \n",
    "    print(f\"\\nCurrent load distribution:\")\n",
    "    print(f\"During PV hours (typically {pv_hours[0]}-{pv_hours[-1]}h): {current_pv_hour_load:.1f} kW\")\n",
    "    print(f\"During non-PV hours: {current_non_pv_hour_load:.1f} kW\")\n",
    "    print(f\"PV hour utilization: {current_pv_hour_load/(current_pv_hour_load+current_non_pv_hour_load)*100:.1f}%\")\n",
    "    \n",
    "    # Visualize load shifting potential\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    # Current pattern\n",
    "    ax1.bar(hourly_patterns.index, hourly_patterns['relay_demand_kw'], \n",
    "            alpha=0.7, label='Relay Demand', color='red')\n",
    "    ax1.plot(hourly_patterns.index, hourly_patterns['pv_production_kw'], \n",
    "             'g-', linewidth=3, label='PV Production')\n",
    "    ax1.set_title('Current Hourly Energy Pattern')\n",
    "    ax1.set_ylabel('Power (kW)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Optimized pattern (simulation)\n",
    "    optimized_demand = hourly_patterns['relay_demand_kw'].copy()\n",
    "    \n",
    "    # Simple optimization: shift 30% of non-PV hour load to PV hours\n",
    "    shift_amount = hourly_patterns.loc[non_pv_hours, 'relay_demand_kw'].mean() * 0.3\n",
    "    optimized_demand[non_pv_hours] -= shift_amount\n",
    "    optimized_demand[pv_hours] += shift_amount * len(non_pv_hours) / len(pv_hours)\n",
    "    \n",
    "    ax2.bar(hourly_patterns.index, optimized_demand, \n",
    "            alpha=0.7, label='Optimized Demand', color='blue')\n",
    "    ax2.plot(hourly_patterns.index, hourly_patterns['pv_production_kw'], \n",
    "             'g-', linewidth=3, label='PV Production')\n",
    "    ax2.set_title('Optimized Hourly Energy Pattern (30% Load Shift)')\n",
    "    ax2.set_xlabel('Hour of Day')\n",
    "    ax2.set_ylabel('Power (kW)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate self-consumption improvement\n",
    "    current_self_consumption = np.minimum(hourly_patterns['relay_demand_kw'], \n",
    "                                         hourly_patterns['pv_production_kw']).sum()\n",
    "    optimized_self_consumption = np.minimum(optimized_demand, \n",
    "                                           hourly_patterns['pv_production_kw']).sum()\n",
    "    \n",
    "    print(f\"\\n=== Self-Consumption Improvement ===\")\n",
    "    print(f\"Current self-consumption: {current_self_consumption:.1f} kWh/day\")\n",
    "    print(f\"Optimized self-consumption: {optimized_self_consumption:.1f} kWh/day\")\n",
    "    print(f\"Improvement: {optimized_self_consumption - current_self_consumption:.1f} kWh/day \")\n",
    "    print(f\"            ({(optimized_self_consumption/current_self_consumption - 1)*100:.1f}% increase)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Thermal Analysis for Predictive Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze thermal characteristics for predictive control\n",
    "if room_data and weather_data is not None and not weather_data.empty:\n",
    "    print(\"=== Thermal Analysis for Predictive Control ===\")\n",
    "    \n",
    "    # Run thermal analysis\n",
    "    thermal_results = thermal_analyzer.analyze_room_dynamics(room_data, weather_data)\n",
    "    \n",
    "    # Extract RC parameters for key rooms\n",
    "    rc_summary = []\n",
    "    \n",
    "    for room_name, room_results in thermal_results.items():\n",
    "        if isinstance(room_results, dict) and 'rc_model' in room_results:\n",
    "            rc_model = room_results['rc_model']\n",
    "            if 'thermal_resistance' in rc_model:\n",
    "                rc_summary.append({\n",
    "                    'Room': room_name,\n",
    "                    'R (°C/W)': rc_model.get('thermal_resistance', 0),\n",
    "                    'C (Wh/°C)': rc_model.get('thermal_capacity', 0),\n",
    "                    'Time Constant (h)': rc_model.get('time_constant', 0),\n",
    "                    'Model R²': rc_model.get('r_squared', 0)\n",
    "                })\n",
    "    \n",
    "    if rc_summary:\n",
    "        rc_df = pd.DataFrame(rc_summary)\n",
    "        rc_df = rc_df.sort_values('Time Constant (h)', ascending=False)\n",
    "        print(\"\\nThermal characteristics by room:\")\n",
    "        print(rc_df.head(10).to_string(index=False))\n",
    "        \n",
    "        # Identify rooms suitable for pre-heating\n",
    "        slow_rooms = rc_df[rc_df['Time Constant (h)'] > 2.0]  # Slow thermal response\n",
    "        fast_rooms = rc_df[rc_df['Time Constant (h)'] <= 1.0]  # Fast thermal response\n",
    "        \n",
    "        print(f\"\\n=== Predictive Control Recommendations ===\")\n",
    "        print(f\"Rooms suitable for pre-heating (slow response): {len(slow_rooms)}\")\n",
    "        if not slow_rooms.empty:\n",
    "            print(\"Top candidates:\")\n",
    "            for _, room in slow_rooms.head(5).iterrows():\n",
    "                print(f\"  - {room['Room']}: τ = {room['Time Constant (h)']:.1f}h\")\n",
    "        \n",
    "        print(f\"\\nRooms requiring just-in-time heating (fast response): {len(fast_rooms)}\")\n",
    "        if not fast_rooms.empty:\n",
    "            print(\"Top candidates:\")\n",
    "            for _, room in fast_rooms.head(5).iterrows():\n",
    "                print(f\"  - {room['Room']}: τ = {room['Time Constant (h)']:.1f}h\")\n",
    "        \n",
    "        # Visualize thermal parameters\n",
    "        if len(rc_df) > 5:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # Time constants\n",
    "            top_rooms = rc_df.head(10)\n",
    "            ax1.barh(range(len(top_rooms)), top_rooms['Time Constant (h)'])\n",
    "            ax1.set_yticks(range(len(top_rooms)))\n",
    "            ax1.set_yticklabels(top_rooms['Room'])\n",
    "            ax1.set_xlabel('Time Constant (hours)')\n",
    "            ax1.set_title('Thermal Time Constants by Room')\n",
    "            ax1.axvline(x=2.0, color='r', linestyle='--', alpha=0.5, label='Pre-heat threshold')\n",
    "            ax1.legend()\n",
    "            \n",
    "            # Model quality\n",
    "            ax2.scatter(rc_df['Time Constant (h)'], rc_df['Model R²'])\n",
    "            ax2.set_xlabel('Time Constant (hours)')\n",
    "            ax2.set_ylabel('Model R²')\n",
    "            ax2.set_title('Model Quality vs Time Constant')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimization Strategy Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile optimization recommendations\n",
    "print(\"=== RELAY OPTIMIZATION STRATEGY SUMMARY ===\")\n",
    "\n",
    "strategies = []\n",
    "\n",
    "# Peak reduction strategy\n",
    "if 'system_totals' in relay_analysis:\n",
    "    current_peak = relay_analysis['system_totals'].get('peak_demand_kw', 0)\n",
    "    if current_peak > 15:  # Significant peak\n",
    "        strategies.append({\n",
    "            'Strategy': 'Peak Demand Reduction',\n",
    "            'Method': 'Relay coordination and staggering',\n",
    "            'Potential': f'{current_peak * 0.2:.1f} kW reduction',\n",
    "            'Implementation': 'Prevent simultaneous operation of correlated rooms'\n",
    "        })\n",
    "\n",
    "# Load shifting strategy\n",
    "if not pv_data.empty:\n",
    "    strategies.append({\n",
    "        'Strategy': 'PV Self-Consumption',\n",
    "        'Method': 'Shift heating loads to PV production hours',\n",
    "        'Potential': '30% increase in self-consumption',\n",
    "        'Implementation': 'Pre-heat during midday, reduce evening heating'\n",
    "    })\n",
    "\n",
    "# Predictive control strategy\n",
    "if rc_summary:\n",
    "    slow_room_count = len(rc_df[rc_df['Time Constant (h)'] > 2.0])\n",
    "    if slow_room_count > 0:\n",
    "        strategies.append({\n",
    "            'Strategy': 'Predictive Pre-heating',\n",
    "            'Method': 'Weather-based anticipatory control',\n",
    "            'Potential': f'{slow_room_count} rooms with slow response',\n",
    "            'Implementation': 'Start heating 2-3 hours before occupancy'\n",
    "        })\n",
    "\n",
    "# Price-based optimization\n",
    "if 'prices' in all_data:\n",
    "    strategies.append({\n",
    "        'Strategy': 'Price-Based Optimization',\n",
    "        'Method': 'Shift loads to low-price periods',\n",
    "        'Potential': '15-20% cost reduction',\n",
    "        'Implementation': 'Integrate with electricity price forecasts'\n",
    "    })\n",
    "\n",
    "# Display strategies\n",
    "if strategies:\n",
    "    strategy_df = pd.DataFrame(strategies)\n",
    "    print(strategy_df.to_string(index=False))\n",
    "    \n",
    "    # Calculate combined impact\n",
    "    print(\"\\n=== Combined Optimization Impact ===\")\n",
    "    print(\"Estimated benefits from full implementation:\")\n",
    "    print(f\"- Peak demand reduction: 20-25%\")\n",
    "    print(f\"- Energy cost savings: 15-25%\")\n",
    "    print(f\"- PV self-consumption increase: 30-40%\")\n",
    "    print(f\"- Comfort improvement through predictive control\")\n",
    "    print(f\"- Extended relay lifetime through reduced switching\")\n",
    "\n",
    "# Implementation roadmap\n",
    "print(\"\\n=== Implementation Roadmap ===\")\n",
    "print(\"Phase 1 (Immediate):\")\n",
    "print(\"- Implement basic relay coordination rules\")\n",
    "print(\"- Set maximum simultaneous relay limit\")\n",
    "print(\"- Adjust heating schedules to PV production hours\")\n",
    "\n",
    "print(\"\\nPhase 2 (1-3 months):\")\n",
    "print(\"- Deploy predictive control for slow-response rooms\")\n",
    "print(\"- Integrate weather forecast data\")\n",
    "print(\"- Implement price-based optimization\")\n",
    "\n",
    "print(\"\\nPhase 3 (3-6 months):\")\n",
    "print(\"- Machine learning for occupancy prediction\")\n",
    "print(\"- Advanced optimization with battery storage\")\n",
    "print(\"- Full system integration and automation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}